{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96515341",
   "metadata": {},
   "source": [
    "# **Dataset Creation**\n",
    "### Notebook for the testing and development of a methodology for creating a fully labelled dataset of molecules and their functional groups."
   ]
  },
  {
   "cell_type": "code",
   "id": "3e347fb5",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import rdkit.Chem as Chem\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import math\n",
    "\n",
    "from fg_funcs import save_chunk_results, safe_mol_from_smiles, compute_scaffold_safe, compute_efgs_safe"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "62e714f8",
   "metadata": {},
   "source": [
    "## Dataset Creation\n",
    "#### Starting with the small Pec50 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f218e51f",
   "metadata": {},
   "source": [
    "## Chembl Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47d70a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the chembl data\n",
    "chembl_data = pd.read_csv('data/chembl_35_cleaned.csv',header=None, names=['smiles'])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "184034fc31f3abf3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8cfc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10:55:13] Explicit valence for atom # 7 P, 7, is greater than permitted\n",
      "[10:57:07] Explicit valence for atom # 10 Si, 6, is greater than permitted\n",
      "[10:57:36] Explicit valence for atom # 1 P, 7, is greater than permitted\n",
      "[10:58:45] Explicit valence for atom # 1 As, 7, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted SMILES to RDKit Mol objects for ChEMBL dataset.\n",
      "Generated InChIKeys for ChEMBL dataset.\n"
     ]
    }
   ],
   "source": [
    "# 1. Convert SMILES to RDKit Mol\n",
    "chembl_data['rdkit_mol'] = chembl_data['smiles'].apply(safe_mol_from_smiles)\n",
    "print('Converted SMILES to RDKit Mol objects for ChEMBL dataset.')\n",
    "\n",
    "\n",
    "# 2. Generate InChIKeys\n",
    "chembl_data['inchikey'] = chembl_data['rdkit_mol'].apply(\n",
    "    lambda mol: Chem.MolToInchiKey(mol) if mol is not None else None\n",
    ")\n",
    "print('Generated InChIKeys for ChEMBL dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6b472c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with None values in 'rdkit_mol' or 'inchikey'\n",
    "chembl_data = chembl_data.dropna(subset=['rdkit_mol', 'inchikey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50f23938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "chunk_size = 100000\n",
    "output_dir = \"chembl_chunks\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688a8a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_mols = len(chembl_data)\n",
    "num_chunks = math.ceil(total_mols / chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed1d0f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1/24 (0:100000)...\n",
      "Chunk 1 already computed, skipping.\n",
      "Processing chunk 2/24 (100000:200000)...\n",
      "Chunk 2 already computed, skipping.\n",
      "Processing chunk 3/24 (200000:300000)...\n",
      "Chunk 3 already computed, skipping.\n",
      "Processing chunk 4/24 (300000:400000)...\n",
      "Chunk 4 already computed, skipping.\n",
      "Processing chunk 5/24 (400000:500000)...\n",
      "Chunk 5 already computed, skipping.\n",
      "Processing chunk 6/24 (500000:600000)...\n",
      "Chunk 6 already computed, skipping.\n",
      "Processing chunk 7/24 (600000:700000)...\n",
      "Chunk 7 already computed, skipping.\n",
      "Processing chunk 8/24 (700000:800000)...\n",
      "Chunk 8 already computed, skipping.\n",
      "Processing chunk 9/24 (800000:900000)...\n",
      "Chunk 9 already computed, skipping.\n",
      "Processing chunk 10/24 (900000:1000000)...\n",
      "Chunk 10 already computed, skipping.\n",
      "Processing chunk 11/24 (1000000:1100000)...\n",
      "Chunk 11 already computed, skipping.\n",
      "Processing chunk 12/24 (1100000:1200000)...\n",
      "Chunk 12 already computed, skipping.\n",
      "Processing chunk 13/24 (1200000:1300000)...\n",
      "Chunk 13 already computed, skipping.\n",
      "Processing chunk 14/24 (1300000:1400000)...\n",
      "Chunk 14 already computed, skipping.\n",
      "Processing chunk 15/24 (1400000:1500000)...\n",
      "Chunk 15 already computed, skipping.\n",
      "Processing chunk 16/24 (1500000:1600000)...\n",
      "Chunk 16 already computed, skipping.\n",
      "Processing chunk 17/24 (1600000:1700000)...\n",
      "Chunk 17 already computed, skipping.\n",
      "Processing chunk 18/24 (1700000:1800000)...\n",
      "Chunk 18 already computed, skipping.\n",
      "Processing chunk 19/24 (1800000:1900000)...\n",
      "Chunk 19 already computed, skipping.\n",
      "Processing chunk 20/24 (1900000:2000000)...\n",
      "Chunk 20 already computed, skipping.\n",
      "Processing chunk 21/24 (2000000:2100000)...\n",
      "Chunk 21 already computed, skipping.\n",
      "Processing chunk 22/24 (2100000:2200000)...\n",
      "Chunk 22 already computed, skipping.\n",
      "Processing chunk 23/24 (2200000:2300000)...\n",
      "Chunk 23 already computed, skipping.\n",
      "Processing chunk 24/24 (2300000:2310847)...\n",
      "Chunk 24 already computed, skipping.\n",
      "All PSMIs added to ChEMBL dataset.\n"
     ]
    }
   ],
   "source": [
    "# Process in chunks\n",
    "for chunk_idx in range(num_chunks):\n",
    "    start = chunk_idx * chunk_size\n",
    "    end = min((chunk_idx + 1) * chunk_size, total_mols)\n",
    "    \n",
    "    print(f\"Processing chunk {chunk_idx + 1}/{num_chunks} ({start}:{end})...\")\n",
    "    mols_chunk = chembl_data['rdkit_mol'].iloc[start:end]\n",
    "\n",
    "    # Only compute if the file doesn't already exist (for resumability)\n",
    "    chunk_file = os.path.join(output_dir, f\"chunk_{chunk_idx}.pkl\")\n",
    "    if not os.path.exists(chunk_file):\n",
    "        chunk_results = Parallel(n_jobs=-1)(\n",
    "            delayed(compute_efgs_safe)(mol) for mol in mols_chunk\n",
    "        )\n",
    "        save_chunk_results(output_dir, chunk_idx, chunk_results)\n",
    "    else:\n",
    "        print(f\"Chunk {chunk_idx + 1} already computed, skipping.\")\n",
    "\n",
    "# Recombine results\n",
    "all_results = []\n",
    "for chunk_idx in range(num_chunks):\n",
    "    with open(os.path.join(output_dir, f\"chunk_{chunk_idx}.pkl\"), \"rb\") as f:\n",
    "        chunk_results = pickle.load(f)\n",
    "        all_results.extend(chunk_results)\n",
    "\n",
    "# Store or attach results\n",
    "chembl_data['psmis'] = all_results\n",
    "print('All PSMIs added to ChEMBL dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b0d0a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O=C1C(=N[N]([R])[R])C=N[N]1[R]', '[OH][Car]', '[Nar]', '[Nar]', '[Nar]', '[Nar]']\n"
     ]
    }
   ],
   "source": [
    "print(all_results[0])  # Print the first result to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc5f4622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "chunk_size = 100000\n",
    "scaffold_output_dir = \"chembl_scaffold_chunks\"\n",
    "os.makedirs(scaffold_output_dir, exist_ok=True)\n",
    "\n",
    "total_mols = len(chembl_data)\n",
    "num_chunks = math.ceil(total_mols / chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1943a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing scaffold chunk 1/24 (0:100000)...\n",
      "Scaffold chunk 1 already computed, skipping.\n",
      "Processing scaffold chunk 2/24 (100000:200000)...\n",
      "Scaffold chunk 2 already computed, skipping.\n",
      "Processing scaffold chunk 3/24 (200000:300000)...\n",
      "Scaffold chunk 3 already computed, skipping.\n",
      "Processing scaffold chunk 4/24 (300000:400000)...\n",
      "Scaffold chunk 4 already computed, skipping.\n",
      "Processing scaffold chunk 5/24 (400000:500000)...\n",
      "Scaffold chunk 5 already computed, skipping.\n",
      "Processing scaffold chunk 6/24 (500000:600000)...\n",
      "Scaffold chunk 6 already computed, skipping.\n",
      "Processing scaffold chunk 7/24 (600000:700000)...\n",
      "Scaffold chunk 7 already computed, skipping.\n",
      "Processing scaffold chunk 8/24 (700000:800000)...\n",
      "Scaffold chunk 8 already computed, skipping.\n",
      "Processing scaffold chunk 9/24 (800000:900000)...\n",
      "Scaffold chunk 9 already computed, skipping.\n",
      "Processing scaffold chunk 10/24 (900000:1000000)...\n",
      "Scaffold chunk 10 already computed, skipping.\n",
      "Processing scaffold chunk 11/24 (1000000:1100000)...\n",
      "Scaffold chunk 11 already computed, skipping.\n",
      "Processing scaffold chunk 12/24 (1100000:1200000)...\n",
      "Scaffold chunk 12 already computed, skipping.\n",
      "Processing scaffold chunk 13/24 (1200000:1300000)...\n",
      "Scaffold chunk 13 already computed, skipping.\n",
      "Processing scaffold chunk 14/24 (1300000:1400000)...\n",
      "Scaffold chunk 14 already computed, skipping.\n",
      "Processing scaffold chunk 15/24 (1400000:1500000)...\n",
      "Scaffold chunk 15 already computed, skipping.\n",
      "Processing scaffold chunk 16/24 (1500000:1600000)...\n",
      "Scaffold chunk 16 already computed, skipping.\n",
      "Processing scaffold chunk 17/24 (1600000:1700000)...\n",
      "Scaffold chunk 17 already computed, skipping.\n",
      "Processing scaffold chunk 18/24 (1700000:1800000)...\n",
      "Scaffold chunk 18 already computed, skipping.\n",
      "Processing scaffold chunk 19/24 (1800000:1900000)...\n",
      "Scaffold chunk 19 already computed, skipping.\n",
      "Processing scaffold chunk 20/24 (1900000:2000000)...\n",
      "Scaffold chunk 20 already computed, skipping.\n",
      "Processing scaffold chunk 21/24 (2000000:2100000)...\n",
      "Scaffold chunk 21 already computed, skipping.\n",
      "Processing scaffold chunk 22/24 (2100000:2200000)...\n",
      "Scaffold chunk 22 already computed, skipping.\n",
      "Processing scaffold chunk 23/24 (2200000:2300000)...\n",
      "Scaffold chunk 23 already computed, skipping.\n",
      "Processing scaffold chunk 24/24 (2300000:2310847)...\n",
      "Scaffold chunk 24 already computed, skipping.\n",
      "All scaffolds (as SMILES) added to ChEMBL dataset.\n"
     ]
    }
   ],
   "source": [
    "# Chunked scaffold computation\n",
    "for chunk_idx in range(num_chunks):\n",
    "    start = chunk_idx * chunk_size\n",
    "    end = min((chunk_idx + 1) * chunk_size, total_mols)\n",
    "\n",
    "    print(f\"Processing scaffold chunk {chunk_idx + 1}/{num_chunks} ({start}:{end})...\")\n",
    "    mols_chunk = chembl_data['rdkit_mol'].iloc[start:end]\n",
    "\n",
    "    chunk_file = os.path.join(scaffold_output_dir, f\"chunk_{chunk_idx}.pkl\")\n",
    "    if not os.path.exists(chunk_file):\n",
    "        # Compute scaffold mols\n",
    "        scaffold_mols = Parallel(n_jobs=-1)(\n",
    "            delayed(compute_scaffold_safe)(mol) for mol in mols_chunk\n",
    "        )\n",
    "        # Convert to SMILES\n",
    "        scaffold_smiles = [\n",
    "            Chem.MolToSmiles(mol) if mol else None for mol in scaffold_mols\n",
    "        ]\n",
    "        save_chunk_results(scaffold_output_dir, chunk_idx, scaffold_smiles)\n",
    "    else:\n",
    "        print(f\"Scaffold chunk {chunk_idx + 1} already computed, skipping.\")\n",
    "\n",
    "# Recombine scaffold SMILES\n",
    "all_scaffold_smiles = []\n",
    "for chunk_idx in range(num_chunks):\n",
    "    with open(os.path.join(scaffold_output_dir, f\"chunk_{chunk_idx}.pkl\"), \"rb\") as f:\n",
    "        scaffold_smiles = pickle.load(f)\n",
    "        all_scaffold_smiles.extend(scaffold_smiles)\n",
    "\n",
    "# Store in DataFrame\n",
    "chembl_data['scaffolds'] = all_scaffold_smiles\n",
    "print('All scaffolds (as SMILES) added to ChEMBL dataset.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5908a0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r4/3wxjq8t93d76lfkb5vmhrlpr0000gn/T/ipykernel_44129/3216569144.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chembl_data_final.rename(columns={'psmis': 'fgs'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "chembl_data_final = chembl_data[['smiles', 'inchikey', 'psmis', 'scaffolds']]\n",
    "chembl_data_final.rename(columns={'psmis': 'fgs'}, inplace=True)\n",
    "chembl_data_final.to_csv('data/chembl_35_fg_scaf.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkit-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
