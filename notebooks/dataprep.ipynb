{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70e81113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "from fg_funcs import mol_to_fingerprint, safe_mol_from_smiles, fg_to_array, fp_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edfdbb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = 'data/chembl_35_fg_scaf.csv'\n",
    "if os.path.exists(data_path):\n",
    "    chembl = pd.read_csv(data_path)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Dataset not found at {data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84a1b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each fgs entry to a list\n",
    "chembl['fgs'] = chembl['fgs'].apply(lambda x: eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# drop rows with empty fgs\n",
    "chembl = chembl[chembl['fgs'].notna() & (chembl['fgs'].str.len() > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f96eabc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2310581, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chembl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22e09b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[Nar]', '[R][O][R]', 'O=[C]([R])[N]([R])[R]', '[F][R]', '[R][N]([R])[R]', '[Cl][R]', '[OH][Cal]', '[R][NH][R]', '[O]=[Car]', '[OH][Car]', '[Sar]', '[Oar]', 'O=[C]([R])[O][R]', 'O=[C](O)[R]', 'O=[S](=O)([R])[N]([R])[R]', 'C=C', 'O=[C]([R])[R]', '[R][S][R]', '[NH2][Car]', '[R][Br]', 'C#N', 'O=C([N]([R])[R])[N]([R])[R]', '[NH2][Cal]', 'O=[N+]([O-])[R]', '[R][O]C[O][R]', 'O=C([O][R])[N]([R])[R]', 'O=[S](=O)([R])[R]', 'C#C', 'O=[C]([R])[N]([R])[C](=O)[R]', 'C=C[C](=O)[R]', 'C=CC(=O)[N]([R])[R]', 'C=N[N]([R])[C](=O)[R]', 'C=CC(=O)[O][R]', '[R][N]=C([N]([R])[R])[N]([R])[R]', '[R][N]=C[N]([R])[R]', 'O=[C]([R])[N](O)[R]', '[Nar+]', '[R][I]', 'C=N[N]([R])[R]', 'C=[N][R]', 'O=[C]([R])[N]([R])[S](=O)(=O)[R]', 'C=N[O][R]', '[SH][R]', 'O=[CH][R]', 'O=[C]1[R][N]([R])C(=O)[N]1[R]', 'O=[C]([R])C(=O)[N]([R])[R]', '[R][N+]([R])([R])[R]', 'S=C([N]([R])[R])[N]([R])[R]', '[R][N]=C([S][R])[N]([R])[R]', 'O=[P](O)(O)[R]']\n"
     ]
    }
   ],
   "source": [
    "# Curate dataset using 50 functional groups\n",
    "fgs_list = []\n",
    "for fgs in chembl['fgs']:\n",
    "    if isinstance(fgs, list):\n",
    "        fgs_list.extend(fgs)\n",
    "sorted_fgs = pd.Series(fgs_list).value_counts().head(50).index.tolist()\n",
    "\n",
    "print(sorted_fgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8795cb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1/24...\n",
      "Saving chunk 1/24 to disk...\n",
      "Processing chunk 2/24...\n",
      "Saving chunk 2/24 to disk...\n",
      "Processing chunk 3/24...\n",
      "Saving chunk 3/24 to disk...\n",
      "Processing chunk 4/24...\n",
      "Saving chunk 4/24 to disk...\n",
      "Processing chunk 5/24...\n",
      "Saving chunk 5/24 to disk...\n",
      "Processing chunk 6/24...\n",
      "Saving chunk 6/24 to disk...\n",
      "Processing chunk 7/24...\n",
      "Saving chunk 7/24 to disk...\n",
      "Processing chunk 8/24...\n",
      "Saving chunk 8/24 to disk...\n",
      "Processing chunk 9/24...\n",
      "Saving chunk 9/24 to disk...\n",
      "Processing chunk 10/24...\n",
      "Saving chunk 10/24 to disk...\n",
      "Processing chunk 11/24...\n",
      "Saving chunk 11/24 to disk...\n",
      "Processing chunk 12/24...\n",
      "Saving chunk 12/24 to disk...\n",
      "Processing chunk 13/24...\n",
      "Saving chunk 13/24 to disk...\n",
      "Processing chunk 14/24...\n",
      "Saving chunk 14/24 to disk...\n",
      "Processing chunk 15/24...\n",
      "Saving chunk 15/24 to disk...\n",
      "Processing chunk 16/24...\n",
      "Saving chunk 16/24 to disk...\n",
      "Processing chunk 17/24...\n",
      "Saving chunk 17/24 to disk...\n",
      "Processing chunk 18/24...\n",
      "Saving chunk 18/24 to disk...\n",
      "Processing chunk 19/24...\n",
      "Saving chunk 19/24 to disk...\n",
      "Processing chunk 20/24...\n",
      "Saving chunk 20/24 to disk...\n",
      "Processing chunk 21/24...\n",
      "Saving chunk 21/24 to disk...\n",
      "Processing chunk 22/24...\n",
      "Saving chunk 22/24 to disk...\n",
      "Processing chunk 23/24...\n",
      "Saving chunk 23/24 to disk...\n",
      "Processing chunk 24/24...\n",
      "Saving chunk 24/24 to disk...\n",
      "Final processed dataset shape: (2283019, 4)\n"
     ]
    }
   ],
   "source": [
    "# Define chunk size\n",
    "chunk_size = 100000\n",
    "num_chunks = (len(chembl) // chunk_size) + 1\n",
    "\n",
    "processed_chunks = []\n",
    "\n",
    "for i in range(num_chunks):\n",
    "    chunk_path = f\"full_chembl_chunks/full_chembl_chunk_{i}.csv\"\n",
    "    if os.path.exists(chunk_path):\n",
    "        print(f\"Chunk {i+1}/{num_chunks} already processed. Skipping...\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"Processing chunk {i+1}/{num_chunks}...\")\n",
    "    \n",
    "        # Extract chunk\n",
    "        chunk = chembl.iloc[i*chunk_size : (i+1)*chunk_size].copy()\n",
    "\n",
    "        chunk['mol'] = chunk['smiles'].apply(safe_mol_from_smiles)\n",
    "        \n",
    "        # Fingerprints and functional group arrays\n",
    "        chunk['fingerprint'] = chunk['mol'].apply(mol_to_fingerprint)\n",
    "        chunk['fingerprint_array'] = chunk['fingerprint'].apply(\n",
    "            lambda x: fp_to_array(x) if x is not None else None\n",
    "        )\n",
    "        chunk['fg_array'] = chunk['fgs'].apply(lambda x: fg_to_array(x, sorted_fgs))\n",
    "\n",
    "        # Convert to numpy arrays\n",
    "        chunk['fingerprint_array'] = chunk['fingerprint_array'].apply(\n",
    "            lambda x: x if isinstance(x, np.ndarray) else np.zeros((2048,), dtype=int)\n",
    "        )\n",
    "        chunk['fg_array'] = chunk['fg_array'].apply(\n",
    "            lambda x: x if isinstance(x, np.ndarray) else np.zeros((len(sorted_fgs),), dtype=int)\n",
    "        )\n",
    "\n",
    "        # Remove rows where fg_array is all zeros\n",
    "        chunk = chunk[chunk['fg_array'].apply(lambda x: np.any(x))]\n",
    "\n",
    "        # Only keep necessary columns\n",
    "        chunk = chunk[['smiles', 'fgs', 'fingerprint_array', 'fg_array']]\n",
    "\n",
    "        # --- INPLACE FIX: Convert arrays to comma-separated strings before saving ---\n",
    "        chunk['fingerprint_array'] = chunk['fingerprint_array'].apply(\n",
    "            lambda x: ','.join(map(str, x.tolist()))\n",
    "        )\n",
    "        chunk['fg_array'] = chunk['fg_array'].apply(\n",
    "            lambda x: ','.join(map(str, x.tolist()))\n",
    "        )\n",
    "\n",
    "        # Save checkpoint\n",
    "        if not os.path.exists(\"full_chembl_chunks\"):\n",
    "            os.makedirs(\"full_chembl_chunks\")\n",
    "        print(f\"Saving chunk {i+1}/{num_chunks} to disk...\")\n",
    "        chunk.to_csv(chunk_path, index=False)\n",
    "\n",
    "# Combine all processed chunks\n",
    "# load processed chunks\n",
    "processed_chunks = []\n",
    "for i in range(num_chunks):\n",
    "    chunk_path = f\"full_chembl_chunks/full_chembl_chunk_{i}.csv\"\n",
    "    if os.path.exists(chunk_path):\n",
    "        processed_chunk = pd.read_csv(chunk_path)\n",
    "        \n",
    "        processed_chunks.append(processed_chunk)\n",
    "    else:\n",
    "        print(f\"Chunk {i+1}/{num_chunks} not found. Skipping...\")\n",
    "        \n",
    "chembl_processed = pd.concat(processed_chunks, ignore_index=True)\n",
    "print(f\"Final processed dataset shape: {chembl_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2df0ee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert fg_array to sparse components\n",
    "chembl_processed['fg_data'] = chembl_processed['fg_array'].apply(\n",
    "    lambda x: sparse.csr_matrix(np.fromstring(x, sep=','))\n",
    ")\n",
    "chembl_processed['fg_data_values'] = chembl_processed['fg_data'].apply(lambda x: x.data.tolist())\n",
    "chembl_processed['fg_indices'] = chembl_processed['fg_data'].apply(lambda x: x.indices.tolist())\n",
    "chembl_processed['fg_indptr'] = chembl_processed['fg_data'].apply(lambda x: x.indptr.tolist())\n",
    "chembl_processed['fg_length'] = chembl_processed['fg_data'].apply(lambda x: x.shape[1])\n",
    "\n",
    "# Same for fingerprint_array\n",
    "chembl_processed['fp_data'] = chembl_processed['fingerprint_array'].apply(\n",
    "    lambda x: sparse.csr_matrix(np.fromstring(x, sep=','))\n",
    ")\n",
    "chembl_processed['fp_data_values'] = chembl_processed['fp_data'].apply(lambda x: x.data.tolist())\n",
    "chembl_processed['fp_indices'] = chembl_processed['fp_data'].apply(lambda x: x.indices.tolist())\n",
    "chembl_processed['fp_indptr'] = chembl_processed['fp_data'].apply(lambda x: x.indptr.tolist())\n",
    "chembl_processed['fp_length'] = chembl_processed['fp_data'].apply(lambda x: x.shape[1])\n",
    "\n",
    "chembl_processed = chembl_processed.drop(columns=['fg_array', 'fingerprint_array', 'fg_data', 'fp_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "396c8ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to data/chembl_35_fg_full.csv\n",
      "Deleted directory: full_chembl_chunks\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Save the processed data to a CSV file\n",
    "output_file = 'data/chembl_35_fg_full.csv'\n",
    "chembl_processed.to_csv(output_file, index=False)\n",
    "print(f\"Processed data saved to {output_file}\")\n",
    "\n",
    "chunks_dir = \"full_chembl_chunks\"\n",
    "if os.path.exists(chunks_dir):\n",
    "    shutil.rmtree(chunks_dir)\n",
    "    print(f\"Deleted directory: {chunks_dir}\")\n",
    "else:\n",
    "    print(f\"Directory not found: {chunks_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53ef0616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "smiles",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "fgs",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "fg_data_values",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "fg_indices",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "fg_indptr",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "fg_length",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fp_data_values",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "fp_indices",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "fp_indptr",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "fp_length",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "af5de55f-e73c-4d3f-90b6-c32a9165df14",
       "rows": [
        [
         "0",
         "CC1=NN(c2ccc(C)c(C)c2)C(=O)/C1=N\\Nc1cccc(-c2cccc(-c3nnn[nH]3)c2)c1O",
         "['O=C1C(=N[N]([R])[R])C=N[N]1[R]', '[OH][Car]', '[Nar]', '[Nar]', '[Nar]', '[Nar]']",
         "[1.0, 1.0]",
         "[0, 9]",
         "[0, 2]",
         "50",
         "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]",
         "[73, 74, 83, 98, 186, 191, 202, 233, 247, 293, 314, 352, 369, 378, 503, 567, 591, 650, 673, 725, 736, 807, 871, 873, 875, 879, 929, 935, 937, 984, 1007, 1027, 1039, 1057, 1088, 1114, 1152, 1160, 1164, 1224, 1273, 1283, 1310, 1347, 1380, 1391, 1543, 1602, 1609, 1619, 1623, 1691, 1696, 1722, 1747, 1750, 1779, 1800, 1825, 1873, 1946, 1953]",
         "[0, 62]",
         "2048"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>fgs</th>\n",
       "      <th>fg_data_values</th>\n",
       "      <th>fg_indices</th>\n",
       "      <th>fg_indptr</th>\n",
       "      <th>fg_length</th>\n",
       "      <th>fp_data_values</th>\n",
       "      <th>fp_indices</th>\n",
       "      <th>fp_indptr</th>\n",
       "      <th>fp_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC1=NN(c2ccc(C)c(C)c2)C(=O)/C1=N\\Nc1cccc(-c2cc...</td>\n",
       "      <td>['O=C1C(=N[N]([R])[R])C=N[N]1[R]', '[OH][Car]'...</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>[0, 9]</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>50</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[73, 74, 83, 98, 186, 191, 202, 233, 247, 293,...</td>\n",
       "      <td>[0, 62]</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles  \\\n",
       "0  CC1=NN(c2ccc(C)c(C)c2)C(=O)/C1=N\\Nc1cccc(-c2cc...   \n",
       "\n",
       "                                                 fgs fg_data_values  \\\n",
       "0  ['O=C1C(=N[N]([R])[R])C=N[N]1[R]', '[OH][Car]'...     [1.0, 1.0]   \n",
       "\n",
       "  fg_indices fg_indptr  fg_length  \\\n",
       "0     [0, 9]    [0, 2]         50   \n",
       "\n",
       "                                      fp_data_values  \\\n",
       "0  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "\n",
       "                                          fp_indices fp_indptr  fp_length  \n",
       "0  [73, 74, 83, 98, 186, 191, 202, 233, 247, 293,...   [0, 62]       2048  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chembl_processed.head(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkit-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
