{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e35dc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from VAE import (\n",
    "    train_conditional_vae, \n",
    "    train_conditional_subspace_vae, \n",
    "    train_discover_vae, \n",
    "    train_base_model,\n",
    "    FingerprintDataset,\n",
    "    BaseVAETrainer,\n",
    "    ConditionalVAETrainer,\n",
    "    ConditionalSubspaceVAETrainer,\n",
    "    DiscoverVAETrainer\n",
    "    )\n",
    "from fg_funcs import (\n",
    "    extract_and_save_latents,\n",
    "    extract_prefixed_arrays,\n",
    "    get_nearest_neighbors,\n",
    "    metric\n",
    ")\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94b60645",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = []\n",
    "GET_LATENTS = False\n",
    "VIS_CUR = False\n",
    "VIS_FULL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c72ccbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dims = [4, 8, 16]  # You can change this to test different latent dimensions\n",
    "encoder_hidden_dims = [1024, 512, 256, 128]\n",
    "decoder_hidden_dims = [128, 512]  \n",
    "decoder_z_hidden_dims = [128, 512]  # Decoder layers for DISCoVeR\n",
    "latent_dims_z = [4, 8, 16] # for CSVAE and DISCoVeR\n",
    "latent_dims_w = [2, 4, 8] # for CSVAE and DISCoVeR\n",
    "encoder_hidden_dims_z = [1024, 512, 256, 128] # for CSVAE and DISCoVeR\n",
    "encoder_hidden_dims_w = [1024, 512, 256, 128] # for CSVAE and DISCoVeR\n",
    "adversarial_hidden_dims = [8] \n",
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "max_epochs = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fef2fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "for latent_dim, latent_dim_z, latent_dim_w in zip(latent_dims, latent_dims_z, latent_dims_w):\n",
    "    for MODEL in TRAIN:\n",
    "        model_type, dataset_type = MODEL.split('_')\n",
    "\n",
    "        if dataset_type == 'CUR':\n",
    "            # Load the curated dataset\n",
    "            curated_dataset = pd.read_pickle('data/chembl_35_fg_scaf_curated.pkl')\n",
    "\n",
    "            # Convert the fingerprint to numpy arrays\n",
    "            curated_dataset['fingerprint_array'] = curated_dataset['fingerprint_array'].apply(lambda x: x if isinstance(x, np.ndarray) else np.zeros((2048,), dtype=int))\n",
    "            curated_dataset['fg_array'] = curated_dataset['fg_array'].apply(lambda x: x if isinstance(x, np.ndarray) else np.zeros((100,), dtype=int))\n",
    "\n",
    "            MODEL_OUTPUT = 'models/small_models'  # Directory to save trained models\n",
    "            dataset = curated_dataset  # Use the curated dataset for training\n",
    "            sparse = False\n",
    "\n",
    "            input_dim = 2048\n",
    "            fg_dim = 4\n",
    "\n",
    "        elif dataset_type == 'FULL':\n",
    "            # Load the full dataset\n",
    "            full_dataset = pd.read_csv(\"data/chembl_35_fg_full.csv\")\n",
    "\n",
    "            MODEL_OUTPUT = 'models/large_models'  # Directory to save trained models\n",
    "            dataset = full_dataset  # Use the full dataset for training\n",
    "            sparse = True\n",
    "\n",
    "            input_dim = 2048\n",
    "            fg_dim = 50\n",
    "\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "        if model_type is None:\n",
    "            raise ValueError(\"MODEL must be defined before training.\")\n",
    "        elif model_type == 'Base':\n",
    "\n",
    "            print(\"Training BaseVAE model...\")\n",
    "            \n",
    "\n",
    "            vae_trainer = train_base_model(\n",
    "                dataset=dataset,\n",
    "                input_dim=input_dim,\n",
    "                latent_dim=latent_dim,\n",
    "                fg_dim=fg_dim,  # BaseVAE does not use fg_array for logging purposes only\n",
    "                encoder_hidden_dims=encoder_hidden_dims,\n",
    "                decoder_hidden_dims=decoder_hidden_dims,\n",
    "                batch_size=batch_size,\n",
    "                learning_rate=learning_rate,\n",
    "                max_epochs=max_epochs,\n",
    "                sparse=sparse\n",
    "            )\n",
    "\n",
    "        elif model_type == 'CVAE':\n",
    "\n",
    "            print(\"Training CVAE model...\")\n",
    "\n",
    "            vae_trainer = train_conditional_vae(\n",
    "                dataset=dataset,\n",
    "                fingerprint_dim=input_dim,\n",
    "                fg_dim=fg_dim,\n",
    "                latent_dim=latent_dim,\n",
    "                encoder_hidden_dims=encoder_hidden_dims,\n",
    "                decoder_hidden_dims=decoder_hidden_dims,\n",
    "                batch_size=batch_size,\n",
    "                learning_rate=learning_rate,\n",
    "                max_epochs=max_epochs,\n",
    "                sparse=sparse\n",
    "            )\n",
    "\n",
    "        elif model_type == 'CSVAE':\n",
    "\n",
    "            print(\"Training CSVAE model based on the NeurIPS 2018 paper...\")\n",
    "\n",
    "\n",
    "            vae_trainer = train_conditional_subspace_vae(\n",
    "                dataset=dataset,\n",
    "                fingerprint_dim=input_dim,\n",
    "                fg_dim=fg_dim,\n",
    "                latent_dim_z=latent_dim_z,\n",
    "                latent_dim_w=latent_dim_w,\n",
    "                encoder_hidden_dims_z=encoder_hidden_dims_z,\n",
    "                encoder_hidden_dims_w=encoder_hidden_dims_w,\n",
    "                decoder_hidden_dims=decoder_hidden_dims,\n",
    "                adversarial_hidden_dims=adversarial_hidden_dims,\n",
    "                batch_size=batch_size,\n",
    "                learning_rate=learning_rate,\n",
    "                max_epochs=max_epochs,\n",
    "                sparse=sparse\n",
    "            )\n",
    "\n",
    "        elif model_type == 'DISCoVeR':\n",
    "\n",
    "            print(\"Training DISCoVeR VAE model...\")\n",
    "\n",
    "            vae_trainer = train_discover_vae(\n",
    "                dataset=dataset,\n",
    "                fingerprint_dim=input_dim,\n",
    "                fg_dim=fg_dim,\n",
    "                latent_dim_z=latent_dim_z,\n",
    "                latent_dim_w=latent_dim_w,\n",
    "                encoder_hidden_dims_z=encoder_hidden_dims_z,\n",
    "                encoder_hidden_dims_w=encoder_hidden_dims_w,\n",
    "                decoder_hidden_dims=decoder_hidden_dims,\n",
    "                decoder_z_hidden_dims=decoder_z_hidden_dims,\n",
    "                adversarial_hidden_dims=adversarial_hidden_dims,\n",
    "                batch_size=batch_size,\n",
    "                learning_rate=learning_rate,\n",
    "                max_epochs=max_epochs,\n",
    "                sparse=sparse\n",
    "            )\n",
    "\n",
    "        # Free memory after each model\n",
    "        del vae_trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57b23434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of models and locations\n",
    "latent_dim = latent_dims[1]\n",
    "small_models = [\n",
    "    (\"Base\", f\"checkpoints/fg_bvae_4_{latent_dim}/best-checkpoint.ckpt\", BaseVAETrainer),\n",
    "    (\"CVAE\", f\"checkpoints/fg_cvae_4_{latent_dim}/best-checkpoint.ckpt\", ConditionalVAETrainer),\n",
    "    (\"CSVAE\", f\"checkpoints/fg_csvae_4_{latent_dim}/best-checkpoint.ckpt\", ConditionalSubspaceVAETrainer),\n",
    "    (\"DISCoVeR\", f\"checkpoints/fg_dvae_4_{latent_dim}/best-checkpoint.ckpt\", DiscoverVAETrainer)\n",
    "]\n",
    "\n",
    "large_models = [\n",
    "    (\"Base\", f\"checkpoints/fg_bvae_50_{latent_dim}/best-checkpoint.ckpt\", BaseVAETrainer),\n",
    "    (\"CVAE\", f\"checkpoints/fg_cvae_50_{latent_dim}/best-checkpoint.ckpt\", ConditionalVAETrainer),\n",
    "    (\"CSVAE\", f\"checkpoints/fg_csvae_50_{latent_dim}/best-checkpoint.ckpt\", ConditionalSubspaceVAETrainer),\n",
    "    (\"DISCoVeR\", f\"checkpoints/fg_dvae_50_{latent_dim}/best-checkpoint.ckpt\", DiscoverVAETrainer)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c590c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GET_LATENTS:\n",
    "    # Create a test DataLoader\n",
    "    curated_dataset = pd.read_pickle('data/chembl_35_fg_scaf_curated.pkl')\n",
    "\n",
    "    # Convert the fingerprint to numpy arrays\n",
    "    curated_dataset['fingerprint_array'] = curated_dataset['fingerprint_array'].apply(lambda x: x if isinstance(x, np.ndarray) else np.zeros((2048,), dtype=int))\n",
    "    curated_dataset['fg_array'] = curated_dataset['fg_array'].apply(lambda x: x if isinstance(x, np.ndarray) else np.zeros((100,), dtype=int))\n",
    "\n",
    "    # Split the dataset into train and test sets\n",
    "    train_data, test_data = train_test_split(curated_dataset, test_size=0.2, random_state=42)\n",
    "    val_data, test_data = train_test_split(test_data, test_size=0.2, random_state=42)\n",
    "\n",
    "    test_dataset = FingerprintDataset(test_data, sparse=False)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "    device = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Extract and save latents for small models\n",
    "    for model_name, model_path, model_class in small_models:\n",
    "        extract_and_save_latents(\n",
    "            model_path=model_path,\n",
    "            dataloader=test_dataloader,\n",
    "            model_type=model_name,\n",
    "            model_class=model_class,\n",
    "            device=device\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "774769b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GET_LATENTS:    \n",
    "    try:\n",
    "        # Re-run the extraction and saving process for the full dataset\n",
    "        full_dataset = pd.read_csv(\"data/chembl_35_fg_full.csv\")\n",
    "\n",
    "        train_full, test_full = train_test_split(full_dataset, test_size=0.2, random_state=42)\n",
    "        val_full, test_full = train_test_split(test_full, test_size=0.2, random_state=42)\n",
    "\n",
    "        test_full_dataset = FingerprintDataset(test_full, sparse=True)\n",
    "        full_dataloader = DataLoader(test_full_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "        for model_name, model_path, model_class in large_models:\n",
    "            extract_and_save_latents(\n",
    "                model_path=model_path,\n",
    "                dataloader=full_dataloader,\n",
    "                model_type=model_name,\n",
    "                model_class=model_class,\n",
    "                device=\"mps\"\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while extracting latents: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49ce3af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and plot base latents UMAP\n",
    "latent_dim = latent_dim\n",
    "cur_size = 80000\n",
    "full_size = 1826415\n",
    "\n",
    "if VIS_CUR:\n",
    "    try:\n",
    "        base_latents_cur = extract_prefixed_arrays(f'latents/latents_Base_{cur_size}_{latent_dim}.csv', ['z', 'y'])\n",
    "        cvae_latents_cur = extract_prefixed_arrays(f'latents/latents_CVAE_{cur_size}_{latent_dim}.csv', ['z', 'y'])\n",
    "        csvae_latents_cur = extract_prefixed_arrays(f'latents/latents_CSVAE_{cur_size}_{latent_dim}.csv', ['z', 'w', 'y'])\n",
    "        discover_latents_cur = extract_prefixed_arrays(f'latents/latents_DISCoVeR_{cur_size}_{latent_dim}.csv', ['z', 'w', 'y'])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while loading current latents: {e}\")\n",
    "\n",
    "if VIS_FULL:\n",
    "    try:\n",
    "        base_latents_full = extract_prefixed_arrays(f'latents/latents_Base_{full_size}_{latent_dim}.csv', ['z', 'y'])\n",
    "        cvae_latents_full = extract_prefixed_arrays(f'latents/latents_CVAE_{full_size}_{latent_dim}.csv', ['z', 'y'])\n",
    "        csvae_latents_full = extract_prefixed_arrays(f'latents/latents_CSVAE_{full_size}_{latent_dim}.csv', ['z', 'w', 'y'])\n",
    "        discover_latents_full = extract_prefixed_arrays(f'latents/latents_DISCoVeR_{full_size}_{latent_dim}.csv', ['z', 'w', 'y'])\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while loading full latents: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b28cb62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fg_funcs import visualize_latent_space_per_fg\n",
    "\n",
    "method = 'umap'\n",
    "\n",
    "if VIS_CUR:\n",
    "    try:\n",
    "        # Visualize the latent space\n",
    "        visualize_latent_space_per_fg(base_latents_cur['z'], base_latents_cur['y'], method, sample_size=5000, combined_title=f'Base VAE {method.upper()} {latent_dim} {'Test Set' if cur_size < 50000 else 'Train Set'}', per_fg_title=f'Base VAE by FG {method.upper()} {latent_dim} {'Test Set' if cur_size < 50000 else 'Train Set'}', save_path=f'images/base_vae_cur_{latent_dim}_{cur_size}/')\n",
    "        visualize_latent_space_per_fg(cvae_latents_cur['z'], cvae_latents_cur['y'], method, sample_size=5000, combined_title=f'CVAE {method.upper()} {latent_dim} {'Test Set' if cur_size < 50000 else 'Train Set'}', per_fg_title=f'CVAE by FG {method.upper()} {latent_dim} {'Test Set' if cur_size < 50000 else 'Train Set'}', save_path=f'images/cvae_cur_{latent_dim}_{cur_size}/')\n",
    "        visualize_latent_space_per_fg(csvae_latents_cur['z'], csvae_latents_cur['y'], method, sample_size=5000, combined_title=f'CSVAE {method.upper()} {latent_dim} {'Test Set' if cur_size < 50000 else 'Train Set'}', per_fg_title=f'CSVAE by FG {method.upper()} {latent_dim} {'Test Set' if cur_size < 50000 else 'Train Set'}', save_path=f'images/csvae_cur_{latent_dim}_{cur_size}/')\n",
    "        visualize_latent_space_per_fg(discover_latents_cur['z'], discover_latents_cur['y'], method, sample_size=5000, combined_title=f'Discover {method.upper()} {latent_dim} {'Test Set' if cur_size < 50000 else 'Train Set'}', per_fg_title=f'Discover by FG {method.upper()} {latent_dim} {'Test Set' if cur_size < 50000 else 'Train Set'}', save_path=f'images/discover_cur_{latent_dim}_{cur_size}/')\n",
    "        visualize_latent_space_per_fg(csvae_latents_cur['w'], csvae_latents_cur['y'], method, sample_size=5000, combined_title=f'CSVAE {method.upper()} {latent_dim/2} {'Test Set' if cur_size < 50000 else 'Train Set'}', per_fg_title=f'CSVAE by FG {method.upper()} {latent_dim/2} {'Test Set' if cur_size < 50000 else 'Train Set'}', save_path=f'images/csvae_cur_w_{latent_dim}_{cur_size}/')\n",
    "        visualize_latent_space_per_fg(discover_latents_cur['w'], discover_latents_cur['y'], method, sample_size=5000, combined_title=f'Discover {method.upper()} {latent_dim/2} {'Test Set' if cur_size < 50000 else 'Train Set'}', per_fg_title=f'Discover by FG {method.upper()} {latent_dim/2} {'Test Set' if cur_size < 50000 else 'Train Set'}', save_path=f'images/discover_cur_w_{latent_dim}_{cur_size}/')\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while visualizing current latents: {e}\")\n",
    "\n",
    "if VIS_FULL:\n",
    "    try:\n",
    "        visualize_latent_space_per_fg(base_latents_full['z'], base_latents_full['y'], method, sample_size=5000, combined_title=f'Base VAE {method.upper()} {latent_dim}', per_fg_title=f'Base VAE by FG {method.upper()} {latent_dim}', save_path=f'images/base_vae_full_{latent_dim}_{full_size}/')\n",
    "        visualize_latent_space_per_fg(cvae_latents_full['z'], cvae_latents_full['y'], method, sample_size=5000, combined_title=f'CVAE {method.upper()} {latent_dim}', per_fg_title=f'CVAE by FG {method.upper()} {latent_dim}', save_path=f'images/cvae_full_{latent_dim}_{full_size}/')\n",
    "        visualize_latent_space_per_fg(csvae_latents_full['z'], csvae_latents_full['y'], method, sample_size=5000, combined_title=f'CSVAE {method.upper()} {latent_dim}', per_fg_title=f'CSVAE by FG {method.upper()} {latent_dim}', save_path=f'images/csvae_full_{latent_dim}_{full_size}/')\n",
    "        visualize_latent_space_per_fg(discover_latents_full['z'], discover_latents_full['y'], method, sample_size=5000, combined_title=f'Discover {method.upper()} {latent_dim}', per_fg_title=f'Discover by FG {method.upper()} {latent_dim}', save_path=f'images/discover_full_{latent_dim}_{full_size}/')\n",
    "        visualize_latent_space_per_fg(csvae_latents_full['w'], csvae_latents_full['y'], method, sample_size=5000, combined_title=f'CSVAE {method.upper()} {latent_dim}', per_fg_title=f'CSVAE by FG {method.upper()} {latent_dim}', save_path=f'images/csvae_full_w_{latent_dim}_{full_size}/')\n",
    "        visualize_latent_space_per_fg(discover_latents_full['w'], discover_latents_full['y'], method, sample_size=5000, combined_title=f'Discover {method.upper()} {latent_dim}', per_fg_title=f'Discover by FG {method.upper()} {latent_dim}', save_path=f'images/discover_full_w_{latent_dim}_{full_size}/')\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while visualizing full latents: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9c03c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for latent latents_Base_4000_4: 0.738165\n",
      "Metrics for latent latents_Base_4000_8: 0.636715\n",
      "Metrics for latent latents_Base_4000_16: 0.5323399999999999\n",
      "Metrics for latent latents_Base_80000_4: 0.8097952500000001\n",
      "Metrics for latent latents_Base_80000_8: 0.7324422500000001\n",
      "Metrics for latent latents_Base_80000_16: 0.6234390000000001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     41\u001b[39m scores = []\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(latent_sample[\u001b[33m'\u001b[39m\u001b[33my\u001b[39m\u001b[33m'\u001b[39m])):\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     metric_score = metric(nbrs, i, latent_z, fg_counts, labels, \u001b[32m50\u001b[39m)\n\u001b[32m     44\u001b[39m     scores.append(metric_score)\n\u001b[32m     45\u001b[39m mean_score = np.mean(scores)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-UniversityCollegeLondon/UCL Thesis/Code/FG_VAE/fg_funcs.py:656\u001b[39m, in \u001b[36mmetric\u001b[39m\u001b[34m(nbrs, query_index, latent, fg_counts, fg_labels, n_neighbors)\u001b[39m\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(indices):\n\u001b[32m    655\u001b[39m     neighbor_fg = fg_labels[idx]\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m     tanimoto_scores[i] = weighted_tanimoto(fg_labels[query_index], neighbor_fg, weights)\n\u001b[32m    658\u001b[39m avg_weighted_tanimoto = np.mean(tanimoto_scores) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tanimoto_scores) > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0.0\u001b[39m\n\u001b[32m    660\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m avg_weighted_tanimoto\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-UniversityCollegeLondon/UCL Thesis/Code/FG_VAE/fg_funcs.py:632\u001b[39m, in \u001b[36mweighted_tanimoto\u001b[39m\u001b[34m(fg_a, fg_b, weights)\u001b[39m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mweighted_tanimoto\u001b[39m(\n\u001b[32m    625\u001b[39m     fg_a: np.ndarray,\n\u001b[32m    626\u001b[39m     fg_b: np.ndarray,\n\u001b[32m    627\u001b[39m     weights: np.ndarray\n\u001b[32m    628\u001b[39m ) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m    629\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    630\u001b[39m \u001b[33;03m    Compute the weighted Tanimoto similarity between two binary arrays, using provided weights.\u001b[39;00m\n\u001b[32m    631\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m632\u001b[39m     intersection = np.sum(weights * (fg_a * fg_b))\n\u001b[32m    633\u001b[39m     union = np.sum(weights * ((fg_a + fg_b) > \u001b[32m0\u001b[39m))\n\u001b[32m    634\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m intersection / union \u001b[38;5;28;01mif\u001b[39;00m union > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0.0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rdkit-thesis/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:2466\u001b[39m, in \u001b[36msum\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, initial, where)\u001b[39m\n\u001b[32m   2463\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m   2464\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[32m-> \u001b[39m\u001b[32m2466\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _wrapreduction(\n\u001b[32m   2467\u001b[39m     a, np.add, \u001b[33m'\u001b[39m\u001b[33msum\u001b[39m\u001b[33m'\u001b[39m, axis, dtype, out,\n\u001b[32m   2468\u001b[39m     keepdims=keepdims, initial=initial, where=where\n\u001b[32m   2469\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rdkit-thesis/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:86\u001b[39m, in \u001b[36m_wrapreduction\u001b[39m\u001b[34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[39m\n\u001b[32m     83\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     84\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis=axis, out=out, **passkwargs)\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# load all latents into latents list\n",
    "latents = {}\n",
    "models = ['Base', 'CVAE', 'CSVAE', 'DISCoVeR']\n",
    "sizes = ['4000', '80000', '91321', '1826415']\n",
    "dims = ['4','8', '16']\n",
    "\n",
    "for model in models:\n",
    "    if model in ['Base', 'CVAE']:\n",
    "        terms = ['z', 'y']\n",
    "    elif model in ['CSVAE', 'DISCoVeR']:\n",
    "        terms = ['z', 'w', 'y']\n",
    "    for size in sizes:\n",
    "        for dim in dims:\n",
    "            name = f\"latents_{model}_{size}_{dim}\"\n",
    "            latent = f\"latents/{name}.csv\"\n",
    "            latents[name] = extract_prefixed_arrays(latent, terms)\n",
    "\n",
    "# Prepare to collect metrics\n",
    "metrics_rows = []\n",
    "header = ['model', 'size', 'dim', 'latent_type', 'score']\n",
    "\n",
    "for name, latent in latents.items():\n",
    "    # Parse model, size, dim from name\n",
    "    parts = name.split('_')\n",
    "    model = parts[1]\n",
    "    size = parts[2]\n",
    "    dim = parts[3]\n",
    "\n",
    "    fg_counts = latent['y'].sum()\n",
    "\n",
    "    # Take a sample of the latents\n",
    "    if len(latent['y']) > 100000:\n",
    "        latent_sample = latent.sample(n=100000)\n",
    "    else:\n",
    "        latent_sample = latent\n",
    "\n",
    "    # z latent\n",
    "    nbrs, latent_z, labels = get_nearest_neighbors(latents=latent_sample['z'].to_list(), fg_labels=latent_sample['y'].to_list(), n_neighbors=50)\n",
    "    scores = []\n",
    "    for i in range(len(latent_sample['y'])):\n",
    "        metric_score = metric(nbrs, i, latent_z, fg_counts, labels, 50)\n",
    "        scores.append(metric_score)\n",
    "    mean_score = np.mean(scores)\n",
    "    print(f\"Metrics for latent {name}: {mean_score}\")\n",
    "    metrics_rows.append([model, size, dim, 'z', mean_score])\n",
    "\n",
    "    # w latent if present\n",
    "    if 'w' in latent_sample:\n",
    "        nbrs, latent_w, labels = get_nearest_neighbors(latents=latent_sample['w'].to_list(), fg_labels=latent_sample['y'].to_list(), n_neighbors=50)\n",
    "        scores = []\n",
    "        for i in range(len(latent_sample['y'])):\n",
    "            metric_score = metric(nbrs, i, latent_w, fg_counts, labels, 50)\n",
    "            scores.append(metric_score)\n",
    "        mean_score = np.mean(scores)\n",
    "        print(f\"Metrics for latent {name} (w): {mean_score}\")\n",
    "        metrics_rows.append([model, size, dim, 'w', mean_score])\n",
    "\n",
    "# Save to CSV\n",
    "with open('latent_metrics.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(metrics_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73790a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use metric directly on fingerprints\n",
    "fingerprint_metric_df = pd.read_pickle('data/chembl_35_fg_scaf_curated.pkl')\n",
    "\n",
    "fingerprint_train, fingerprint_test = train_test_split(fingerprint_metric_df, test_size=0.2, random_state=42)\n",
    "fingerprint_val, fingerprint_test = train_test_split(fingerprint_test, test_size=0.2, random_state=42)\n",
    "\n",
    "nbrs, fingerprints, labels = get_nearest_neighbors(latents=fingerprint_train['fingerprint_array'].to_list(), fg_labels=fingerprint_train['fg_array'].to_list(), n_neighbors=50)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for i in range(len(fingerprints)):\n",
    "    score = metric(nbrs, i, fingerprints, fingerprint_train['fg_array'].sum(), labels, 50)\n",
    "    scores.append(score)\n",
    "\n",
    "print(scores.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkit-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
