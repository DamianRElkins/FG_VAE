{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e35dc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import os\n",
    "import random\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, AllChem, DataStructs, QED\n",
    "from efgs import get_dec_fgs\n",
    "import io\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import re\n",
    "\n",
    "from VAE import (\n",
    "    train_conditional_vae, \n",
    "    train_conditional_subspace_vae, \n",
    "    train_discover_vae, \n",
    "    train_base_model,\n",
    "    FingerprintDataset,\n",
    "    BaseVAETrainer,\n",
    "    ConditionalVAETrainer,\n",
    "    ConditionalSubspaceVAETrainer,\n",
    "    DiscoverVAETrainer,\n",
    "    )\n",
    "from fg_funcs import (\n",
    "    extract_and_save_latents,\n",
    "    extract_prefixed_arrays,\n",
    "    evaluate_reconstructions,\n",
    "    visualize_latent_space_per_fg,\n",
    "    metric,\n",
    "    get_nearest_neighbors,\n",
    "    visualize_latent_space_tanimoto,\n",
    "    fingerprint_to_bv,\n",
    "    mol_to_fingerprint\n",
    ")\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from rdkit.DataStructs.cDataStructs import TanimotoSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b60645",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = []\n",
    "GET_LATENTS = True\n",
    "GET_EVAL = True\n",
    "VIS_CUR = True\n",
    "VIS_FULL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72ccbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dims = [4, 8, 16]  # You can change this to test different latent dimensions\n",
    "encoder_hidden_dims = [1024, 512, 256, 128]\n",
    "decoder_hidden_dims = [128, 512]  \n",
    "decoder_z_hidden_dims = [128, 512]  # Decoder layers for DISCoVeR\n",
    "latent_dims_z = [4, 8, 16] # for CSVAE and DISCoVeR\n",
    "latent_dims_w = [2, 4, 8] # for CSVAE and DISCoVeR\n",
    "encoder_hidden_dims_z = [1024, 512, 256, 128] # for CSVAE and DISCoVeR\n",
    "encoder_hidden_dims_w = [1024, 512, 256, 128] # for CSVAE and DISCoVeR\n",
    "adversarial_hidden_dims = [8] \n",
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "max_epochs = 5\n",
    "betas = (0.5, 1, 1.5, 2, 3, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fef2fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "for latent_dim, latent_dim_z, latent_dim_w in zip(latent_dims, latent_dims_z, latent_dims_w):\n",
    "    for MODEL in TRAIN:\n",
    "        model_type, dataset_type = MODEL.split('_')\n",
    "\n",
    "        if dataset_type == 'CUR':\n",
    "            # Load the curated dataset\n",
    "            curated_dataset = pd.read_pickle('data/chembl_35_fg_scaf_curated.pkl')\n",
    "\n",
    "            # Convert the fingerprint to numpy arrays\n",
    "            curated_dataset['fingerprint_array'] = curated_dataset['fingerprint_array'].apply(lambda x: x if isinstance(x, np.ndarray) else np.zeros((2048,), dtype=int))\n",
    "            curated_dataset['fg_array'] = curated_dataset['fg_array'].apply(lambda x: x if isinstance(x, np.ndarray) else np.zeros((100,), dtype=int))\n",
    "\n",
    "            MODEL_OUTPUT = 'models/small_models'  # Directory to save trained models\n",
    "            dataset = curated_dataset  # Use the curated dataset for training\n",
    "            sparse = False\n",
    "\n",
    "            input_dim = 2048\n",
    "            fg_dim = 4\n",
    "\n",
    "        elif dataset_type == 'FULL':\n",
    "            # Load the full dataset\n",
    "            full_dataset = pd.read_csv(\"data/chembl_35_fg_full.csv\")\n",
    "\n",
    "            MODEL_OUTPUT = 'models/large_models'  # Directory to save trained models\n",
    "            dataset = full_dataset  # Use the full dataset for training\n",
    "            sparse = True\n",
    "\n",
    "            input_dim = 2048\n",
    "            fg_dim = 50\n",
    "\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "        if model_type is None:\n",
    "            raise ValueError(\"MODEL must be defined before training.\")\n",
    "        elif model_type == 'Base':\n",
    "\n",
    "            print(\"Training BaseVAE model...\")\n",
    "            \n",
    "            print(\"Training with beta=1 ...\")\n",
    "            vae_trainer = train_base_model(\n",
    "                dataset=dataset,\n",
    "                input_dim=input_dim,\n",
    "                latent_dim=latent_dim,\n",
    "                fg_dim=fg_dim,  # BaseVAE does not use fg_array for logging purposes only\n",
    "                encoder_hidden_dims=encoder_hidden_dims,\n",
    "                decoder_hidden_dims=decoder_hidden_dims,\n",
    "                beta=1,\n",
    "                batch_size=batch_size,\n",
    "                learning_rate=learning_rate,\n",
    "                max_epochs=max_epochs,\n",
    "                sparse=sparse\n",
    "            )\n",
    "\n",
    "        elif model_type == 'CVAE':\n",
    "\n",
    "            print(\"Training CVAE model...\")\n",
    "\n",
    "            vae_trainer = train_conditional_vae(\n",
    "                dataset=dataset,\n",
    "                fingerprint_dim=input_dim,\n",
    "                fg_dim=fg_dim,\n",
    "                latent_dim=latent_dim,\n",
    "                encoder_hidden_dims=encoder_hidden_dims,\n",
    "                decoder_hidden_dims=decoder_hidden_dims,\n",
    "                batch_size=batch_size,\n",
    "                learning_rate=learning_rate,\n",
    "                max_epochs=max_epochs,\n",
    "                sparse=sparse\n",
    "            )\n",
    "\n",
    "        elif model_type == 'CSVAE':\n",
    "\n",
    "            print(\"Training CSVAE model based on the NeurIPS 2018 paper...\")\n",
    "\n",
    "\n",
    "            vae_trainer = train_conditional_subspace_vae(\n",
    "                dataset=dataset,\n",
    "                fingerprint_dim=input_dim,\n",
    "                fg_dim=fg_dim,\n",
    "                latent_dim_z=latent_dim_z,\n",
    "                latent_dim_w=latent_dim_w,\n",
    "                encoder_hidden_dims_z=encoder_hidden_dims_z,\n",
    "                encoder_hidden_dims_w=encoder_hidden_dims_w,\n",
    "                decoder_hidden_dims=decoder_hidden_dims,\n",
    "                adversarial_hidden_dims=adversarial_hidden_dims,\n",
    "                batch_size=batch_size,\n",
    "                learning_rate=learning_rate,\n",
    "                max_epochs=max_epochs,\n",
    "                sparse=sparse\n",
    "            )\n",
    "\n",
    "        elif model_type == 'DISCoVeR':\n",
    "\n",
    "            print(\"Training DISCoVeR VAE model...\")\n",
    "\n",
    "            vae_trainer = train_discover_vae(\n",
    "                dataset=dataset,\n",
    "                fingerprint_dim=input_dim,\n",
    "                fg_dim=fg_dim,\n",
    "                latent_dim_z=latent_dim_z,\n",
    "                latent_dim_w=latent_dim_w,\n",
    "                encoder_hidden_dims_z=encoder_hidden_dims_z,\n",
    "                encoder_hidden_dims_w=encoder_hidden_dims_w,\n",
    "                decoder_hidden_dims=decoder_hidden_dims,\n",
    "                decoder_z_hidden_dims=decoder_z_hidden_dims,\n",
    "                adversarial_hidden_dims=adversarial_hidden_dims,\n",
    "                batch_size=batch_size,\n",
    "                learning_rate=learning_rate,\n",
    "                max_epochs=max_epochs,\n",
    "                sparse=sparse\n",
    "            )\n",
    "\n",
    "        # Free memory after each model\n",
    "        del vae_trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c590c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GET_LATENTS:\n",
    "    # Create a test DataLoader\n",
    "    curated_dataset = pd.read_pickle('data/chembl_35_fg_scaf_curated.pkl')\n",
    "\n",
    "    # Convert the fingerprint to numpy arrays\n",
    "    curated_dataset['fingerprint_array'] = curated_dataset['fingerprint_array'].apply(lambda x: x if isinstance(x, np.ndarray) else np.zeros((2048,), dtype=int))\n",
    "    curated_dataset['fg_array'] = curated_dataset['fg_array'].apply(lambda x: x if isinstance(x, np.ndarray) else np.zeros((100,), dtype=int))\n",
    "\n",
    "    # Split the dataset into train and test sets\n",
    "    train_data, test_data = train_test_split(curated_dataset, test_size=0.2, random_state=42)\n",
    "    val_data, test_data = train_test_split(test_data, test_size=0.2, random_state=42)\n",
    "\n",
    "    test_dataset = FingerprintDataset(test_data, sparse=False)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    train_dataset = FingerprintDataset(train_data, sparse=False)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    device = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "    dataset_partition = 'Test'\n",
    "\n",
    "    for latent_dim in latent_dims:\n",
    "        small_models = [\n",
    "            (\"Base\", f\"checkpoints/fg_bvae_4_{latent_dim}_1/best-checkpoint.ckpt\", BaseVAETrainer),\n",
    "            (\"CVAE\", f\"checkpoints/fg_cvae_4_{latent_dim}/best-checkpoint.ckpt\", ConditionalVAETrainer),\n",
    "            (\"CSVAE\", f\"checkpoints/fg_csvae_4_{latent_dim}/best-checkpoint.ckpt\", ConditionalSubspaceVAETrainer),\n",
    "            (\"DISCoVeR\", f\"checkpoints/fg_dvae_4_{latent_dim}/best-checkpoint.ckpt\", DiscoverVAETrainer),\n",
    "        ]\n",
    "\n",
    "        # Extract and save latents for small models\n",
    "        for model_name, model_path, model_class in small_models:\n",
    "            extract_and_save_latents(\n",
    "                model_path=model_path,\n",
    "                dataloader=test_dataloader if dataset_partition == 'Test' else train_dataloader,\n",
    "                model_type=model_name,\n",
    "                model_class=model_class,\n",
    "                device=device,\n",
    "                output_csv=f\"latents/latents_{model_name}_{len(test_dataset) if dataset_partition == 'Test' else len(train_dataset)}_{latent_dim}_{beta}.csv\"\n",
    "            ), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97679f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GET_EVAL:\n",
    "    # Create a test DataLoader\n",
    "    curated_dataset = pd.read_pickle('data/chembl_35_fg_scaf_curated.pkl')\n",
    "\n",
    "    # Convert the fingerprint to numpy arrays\n",
    "    curated_dataset['fingerprint_array'] = curated_dataset['fingerprint_array'].apply(lambda x: x if isinstance(x, np.ndarray) else np.zeros((2048,), dtype=int))\n",
    "    curated_dataset['fg_array'] = curated_dataset['fg_array'].apply(lambda x: x if isinstance(x, np.ndarray) else np.zeros((100,), dtype=int))\n",
    "\n",
    "    # Split the dataset into train and test sets\n",
    "    train_data, test_data = train_test_split(curated_dataset, test_size=0.2, random_state=42)\n",
    "    val_data, test_data = train_test_split(test_data, test_size=0.2, random_state=42)\n",
    "\n",
    "    test_dataset = FingerprintDataset(test_data, sparse=False)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "    device = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Create list of models and locations\n",
    "    for beta in betas:\n",
    "        for latent_dim in latent_dims:\n",
    "            small_models = [\n",
    "                (\"Base\", f\"checkpoints/fg_bvae_4_{latent_dim}_{beta}/best-checkpoint.ckpt\", BaseVAETrainer),\n",
    "                # (\"CVAE\", f\"checkpoints/fg_cvae_4_{latent_dim}/best-checkpoint.ckpt\", ConditionalVAETrainer),\n",
    "                # (\"CSVAE\", f\"checkpoints/fg_csvae_4_{latent_dim}/best-checkpoint.ckpt\", ConditionalSubspaceVAETrainer),\n",
    "                # (\"DISCoVeR\", f\"checkpoints/fg_dvae_4_{latent_dim}/best-checkpoint.ckpt\", DiscoverVAETrainer)\n",
    "            ]\n",
    "\n",
    "            # Extract and save latents for small models\n",
    "            for model_name, model_path, model_class in small_models:\n",
    "                evaluate_reconstructions(\n",
    "                    model_path=model_path,\n",
    "                    dataloader=test_dataloader,\n",
    "                    model_type=model_name,\n",
    "                    model_class=model_class,\n",
    "                    device=device,\n",
    "                    thresholds=np.arange(0.4, 0.7, 0.02)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774769b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dims = [4, 8, 16]  # You can change this to test different latent dimensions\n",
    "if GET_LATENTS:    \n",
    "    try:\n",
    "        # Set partition to either 'test' or 'train'\n",
    "        partition = 'test'  # or 'train'\n",
    "\n",
    "        full_dataset = pd.read_csv(\"data/chembl_35_fg_full.csv\")\n",
    "        train_full, test_full = train_test_split(full_dataset, test_size=0.2, random_state=42)\n",
    "        val_full, test_full = train_test_split(test_full, test_size=0.2, random_state=42)\n",
    "\n",
    "        if partition == 'test':\n",
    "            data_full = test_full\n",
    "        elif partition == 'train':\n",
    "            data_full = train_full\n",
    "        else:\n",
    "            raise ValueError(\"partition must be 'test' or 'train'\")\n",
    "\n",
    "        smiles_list = data_full['smiles'].tolist()\n",
    "        full_dataset_obj = FingerprintDataset(data_full, sparse=True)\n",
    "        full_dataloader = DataLoader(full_dataset_obj, batch_size=64, shuffle=False)\n",
    "\n",
    "        for latent_dim in latent_dims:\n",
    "            large_models = [\n",
    "                (\"Base\", f\"checkpoints/fg_bvae_50_{latent_dim}_1/best-checkpoint.ckpt\", BaseVAETrainer),\n",
    "                # (\"CVAE\", f\"checkpoints/fg_cvae_50_{latent_dim}/best-checkpoint.ckpt\", ConditionalVAETrainer),\n",
    "                # (\"CSVAE\", f\"checkpoints/fg_csvae_50_{latent_dim}/best-checkpoint.ckpt\", ConditionalSubspaceVAETrainer),\n",
    "                # (\"DISCoVeR\", f\"checkpoints/fg_dvae_50_{latent_dim}/best-checkpoint.ckpt\", DiscoverVAETrainer)\n",
    "            ]\n",
    "\n",
    "            for model_name, model_path, model_class in large_models:\n",
    "                extract_and_save_latents(\n",
    "                    model_path=model_path,\n",
    "                    dataloader=full_dataloader,\n",
    "                    model_type=model_name,\n",
    "                    model_class=model_class,\n",
    "                    device=\"mps\",\n",
    "                    smiles_list=smiles_list,\n",
    "                    output_csv=f\"latents/latents_{model_name}_{len(data_full)}_{latent_dim}.csv\"\n",
    "                )\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while extracting latents: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88d8d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dims = [8,16]  # You can change this to test different latent dimensions\n",
    "if GET_EVAL:\n",
    "    full_dataset = pd.read_csv(\"data/chembl_35_fg_full.csv\")\n",
    "\n",
    "    train_full, test_full = train_test_split(full_dataset, test_size=0.2, random_state=42)\n",
    "    val_full, test_full = train_test_split(test_full, test_size=0.2, random_state=42)\n",
    "\n",
    "    test_full_dataset = FingerprintDataset(test_full, sparse=True)\n",
    "    full_dataloader = DataLoader(test_full_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    for latent_dim in latent_dims:\n",
    "        large_models = [\n",
    "            (\"Base\", f\"checkpoints/fg_bvae_50_{latent_dim}_1/best-checkpoint.ckpt\", BaseVAETrainer),\n",
    "            # (\"CVAE\", f\"checkpoints/fg_cvae_50_{latent_dim}/best-checkpoint.ckpt\", ConditionalVAETrainer),\n",
    "            # (\"CSVAE\", f\"checkpoints/fg_csvae_50_{latent_dim}/best-checkpoint.ckpt\", ConditionalSubspaceVAETrainer),\n",
    "            # (\"DISCoVeR\", f\"checkpoints/fg_dvae_50_{latent_dim}/best-checkpoint.ckpt\", DiscoverVAETrainer)\n",
    "        ]\n",
    "\n",
    "        for model_name, model_path, model_class in large_models:\n",
    "            evaluate_reconstructions(\n",
    "                model_path=model_path,\n",
    "                dataloader=full_dataloader,\n",
    "                model_type=model_name,\n",
    "                model_class=model_class,\n",
    "                device=\"mps\",\n",
    "                thresholds=np.arange(0.5, 0.7, 0.02)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0138c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = {}\n",
    "models = ['Base', 'CSVAE', 'DISCoVeR']\n",
    "sizes = ['1826415']\n",
    "dims = ['4']\n",
    "neighbors = 50\n",
    "\n",
    "for model in models:\n",
    "    if model in ['Base', 'CVAE']:\n",
    "        terms = ['z', 'y']\n",
    "    elif model in ['CSVAE', 'DISCoVeR']:\n",
    "        terms = ['z', 'w', 'y']\n",
    "    for size in sizes:\n",
    "        for dim in dims:\n",
    "            name = f\"latents_{model}_{size}_{dim}\"\n",
    "            latent = f\"latents/{name}.csv\"\n",
    "            latents[name] = extract_prefixed_arrays(latent, terms)\n",
    "            if 'w' in terms:\n",
    "                # Concatenate w and z\n",
    "                latents[name]['wz'] = latents[name].apply(\n",
    "                    lambda row: np.concatenate([row['w'], row['z']]), axis=1\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be03301",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(latents.keys())\n",
    "print(latents['latents_Base_1826415_4'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28cb62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'umap'\n",
    "cur_size = 80000\n",
    "full_size = 1826415\n",
    "latent_dim = 4\n",
    "sample_size = 100000\n",
    "beta = 1\n",
    "fg_names = ['[R][NH][R]', 'O=[C](O)[R]', 'C=C', '[NH2][Car]']\n",
    "\n",
    "for latent_dim in latent_dims:\n",
    "    if VIS_CUR:\n",
    "        try:\n",
    "            # Visualize the latent space\n",
    "            visualize_latent_space_per_fg(latents[f'latents_Base_{cur_size}_{latent_dim}_{beta}']['z'], latents[f'latents_Base_{cur_size}_{latent_dim}_{beta}']['y'], method, sample_size=sample_size, combined_title=f'Base VAE (Beta = {beta}) {method.upper()} {latent_dim} Dimensions {'Test Set' if cur_size < 50000 else 'Train Set'}', per_fg_title=f'Base VAE (Beta = {beta}) by FG {method.upper()} {latent_dim} {'Test Set' if cur_size < 50000 else 'Train Set'}', save_path=f'images/base_vae_cur_{latent_dim}_{cur_size}_{beta}/', fg_names=fg_names)\n",
    "            visualize_latent_space_per_fg(latents[f'latents_CVAE_{cur_size}_{latent_dim}']['z'], latents[f'latents_CVAE_{cur_size}_{latent_dim}']['y'], method, sample_size=sample_size, combined_title=f'CVAE {method.upper()} {latent_dim} {'Test Set' if cur_size < 50000 else 'Train Set'}', per_fg_title=f'CVAE by FG {method.upper()} {latent_dim} {'Test Set' if cur_size < 50000 else 'Train Set'}', save_path=f'images/cvae_cur_{latent_dim}_{cur_size}/', fg_names=fg_names)\n",
    "            visualize_latent_space_per_fg(latents[f'latents_CSVAE_{cur_size}_{latent_dim}']['z'], latents[f'latents_CSVAE_{cur_size}_{latent_dim}']['y'], method, sample_size=sample_size, combined_title=f'CSVAE {method.upper()} {latent_dim} {'Test Set' if cur_size < 50000 else 'Train Set'}', per_fg_title=f'CSVAE by FG {method.upper()} {latent_dim} {'Test Set' if cur_size < 50000 else 'Train Set'}', save_path=f'images/csvae_cur_{latent_dim}_{cur_size}/', fg_names=fg_names)\n",
    "            visualize_latent_space_per_fg(latents[f'latents_DISCoVeR_{cur_size}_{latent_dim}']['z'], latents[f'latents_DISCoVeR_{cur_size}_{latent_dim}']['y'], method, sample_size=sample_size, combined_title=f'Discover {method.upper()} {latent_dim} {'Test Set' if cur_size < 50000 else 'Train Set'}', per_fg_title=f'Discover by FG {method.upper()} {latent_dim} {'Test Set' if cur_size < 50000 else 'Train Set'}', save_path=f'images/discover_cur_{latent_dim}_{cur_size}/', fg_names=fg_names)\n",
    "            visualize_latent_space_per_fg(latents[f'latents_CSVAE_{cur_size}_{latent_dim}']['w'], latents[f'latents_CSVAE_{cur_size}_{latent_dim}']['y'], method, sample_size=sample_size, combined_title=f'CSVAE {method.upper()} {int(latent_dim/2)} {'Test Set' if cur_size < 50000 else 'Train Set'}', per_fg_title=f'CSVAE by FG {method.upper()} {int(latent_dim/2)} {'Test Set' if cur_size < 50000 else 'Train Set'}', save_path=f'images/csvae_cur_w_{latent_dim}_{cur_size}/', fg_names=fg_names)\n",
    "            visualize_latent_space_per_fg(latents[f'latents_DISCoVeR_{cur_size}_{latent_dim}']['w'], latents[f'latents_DISCoVeR_{cur_size}_{latent_dim}']['y'], method, sample_size=sample_size, combined_title=f'Discover {method.upper()} {int(latent_dim/2)} {'Test Set' if cur_size < 50000 else 'Train Set'}', per_fg_title=f'Discover by FG {method.upper()} {int(latent_dim/2)} {'Test Set' if cur_size < 50000 else 'Train Set'}', save_path=f'images/discover_cur_w_{latent_dim}_{cur_size}/', fg_names=fg_names)\n",
    "            visualize_latent_space_per_fg(latents[f'latents_CSVAE_{cur_size}_{latent_dim}']['wz'], latents[f'latents_CSVAE_{cur_size}_{latent_dim}']['y'], method, sample_size=sample_size, combined_title=f'CSVAE {method.upper()} {latent_dim+int(latent_dim/2)} {'Test Set' if cur_size < 50000 else 'Train Set'}', per_fg_title=f'CSVAE WZ by FG {method.upper()} {latent_dim+int(latent_dim/2)} {'Test Set' if cur_size < 50000 else 'Train Set'}', save_path=f'images/csvae_cur_wz_{latent_dim}_{cur_size}/', fg_names=fg_names)\n",
    "            visualize_latent_space_per_fg(latents[f'latents_DISCoVeR_{cur_size}_{latent_dim}']['wz'], latents[f'latents_DISCoVeR_{cur_size}_{latent_dim}']['y'], method, sample_size=sample_size, combined_title=f'Discover {method.upper()} {latent_dim+int(latent_dim/2)} {'Test Set' if cur_size < 50000 else 'Train Set'}', per_fg_title=f'Discover WZ by FG {method.upper()} {latent_dim+int(latent_dim/2)} {'Test Set' if cur_size < 50000 else 'Train Set'}', save_path=f'images/discover_cur_wz_{latent_dim}_{cur_size}/', fg_names=fg_names)\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while visualizing current latents: {e}\")\n",
    "\n",
    "    if VIS_FULL:\n",
    "        try:\n",
    "            visualize_latent_space_per_fg(latents[f'latents_Base_{full_size}_50']['z'], latents[f'latents_Base_{full_size}_50']['y'], method, sample_size=5000, combined_title=f'Base VAE {method.upper()} {latent_dim}', per_fg_title=f'Base VAE by FG {method.upper()} {latent_dim}', save_path=f'images/base_vae_full_{latent_dim}_{full_size}/')\n",
    "            visualize_latent_space_per_fg(latents[f'latents_CVAE_{full_size}_50']['z'], latents[f'latents_CVAE_{full_size}_50']['y'], method, sample_size=5000, combined_title=f'CVAE {method.upper()} {latent_dim}', per_fg_title=f'CVAE by FG {method.upper()} {latent_dim}', save_path=f'images/cvae_full_{latent_dim}_{full_size}/')\n",
    "            visualize_latent_space_per_fg(latents[f'latents_CSVAE_{full_size}_50']['z'], latents[f'latents_CSVAE_{full_size}_50']['y'], method, sample_size=5000, combined_title=f'CSVAE {method.upper()} {latent_dim}', per_fg_title=f'CSVAE by FG {method.upper()} {latent_dim}', save_path=f'images/csvae_full_{latent_dim}_{full_size}/')\n",
    "            visualize_latent_space_per_fg(latents[f'latents_DISCoVeR_{full_size}_50']['z'], latents[f'latents_DISCoVeR_{full_size}_50']['y'], method, sample_size=5000, combined_title=f'Discover {method.upper()} {latent_dim}', per_fg_title=f'Discover by FG {method.upper()} {latent_dim}', save_path=f'images/discover_full_{latent_dim}_{full_size}/')\n",
    "            visualize_latent_space_per_fg(latents[f'latents_CSVAE_{full_size}_50']['w'], latents[f'latents_CSVAE_{full_size}_50']['y'], method, sample_size=5000, combined_title=f'CSVAE {method.upper()} {latent_dim}', per_fg_title=f'CSVAE by FG {method.upper()} {latent_dim}', save_path=f'images/csvae_full_w_{latent_dim}_{full_size}/')\n",
    "            visualize_latent_space_per_fg(latents[f'latents_DISCoVeR_{full_size}_50']['w'], latents[f'latents_DISCoVeR_{full_size}_50']['y'], method, sample_size=5000, combined_title=f'Discover {method.upper()} {latent_dim}', per_fg_title=f'Discover by FG {method.upper()} {latent_dim}', save_path=f'images/discover_full_w_{latent_dim}_{full_size}/')\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while visualizing full latents: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c03c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all latents into latents list\n",
    "\n",
    "# Prepare to collect metrics\n",
    "metrics_rows = []\n",
    "header = ['model', 'size', 'dim', 'beta', 'latent_type', 'score']\n",
    "\n",
    "# Only outer progress bar\n",
    "for name, latent in tqdm(latents.items(), desc=\"Processing latent sets\", dynamic_ncols=True):\n",
    "    parts = name.split('_')\n",
    "    model, size, dim = parts[1], parts[2], parts[3]\n",
    "    fg_counts = latent['y'].sum()\n",
    "\n",
    "    latent_sample = latent.sample(n=50000) if len(latent['y']) > 50000 else latent\n",
    "\n",
    "    def process_latent(latent_key):\n",
    "        nbrs, latent_data, labels = get_nearest_neighbors(\n",
    "            latents=latent_sample[latent_key].to_list(),\n",
    "            fg_labels=np.array(latent_sample['y'].to_list()),\n",
    "            n_neighbors=neighbors\n",
    "        )\n",
    "        scores = [metric(nbrs, i, latent_data, fg_counts, labels, neighbors)\n",
    "                  for i in range(len(latent_sample['y']))]\n",
    "\n",
    "        mean_score = np.mean(scores)\n",
    "        return [model, size, dim, latent_key, mean_score]\n",
    "\n",
    "    metrics_rows.append(process_latent('z'))\n",
    "\n",
    "    if 'w' in latent_sample:\n",
    "        metrics_rows.append(process_latent('w'))\n",
    "        \n",
    "    if 'wz' in latent_sample:\n",
    "        metrics_rows.append(process_latent('wz'))\n",
    "\n",
    "# Save to CSV \n",
    "metrics_path = Path(f'metrics/latent_metrics_{neighbors}.csv')\n",
    "with open(metrics_path, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(metrics_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70beb903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure top-level directories exist\n",
    "Path('images').mkdir(exist_ok=True)\n",
    "Path('interpolations').mkdir(exist_ok=True)\n",
    "\n",
    "# Compute descriptors\n",
    "def compute_descriptors(mol):\n",
    "    return {\n",
    "        'MolWt': Descriptors.MolWt(mol),\n",
    "        'LogP': Descriptors.MolLogP(mol),\n",
    "        'QED': QED.qed(mol),\n",
    "    }\n",
    "\n",
    "def save_molecule_image(mol, smi, output_dir, anchor_mol=None):\n",
    "    # Generate molecule image\n",
    "    # Generate molecule image\n",
    "    img_text, _, _, _ = get_dec_fgs(mol)\n",
    "    img = Image.open(io.BytesIO(img_text)).convert(\"RGB\")  # ensure RGB\n",
    "\n",
    "    # Compute descriptors\n",
    "    desc = compute_descriptors(mol)\n",
    "    desc_text = f\"MolWt: {desc['MolWt']:.2f}, LogP: {desc['LogP']:.2f}, QED: {desc['QED']:.2f}\"\n",
    "\n",
    "    # Compute Tanimoto similarity if anchor provided\n",
    "    if anchor_mol is not None:\n",
    "        fp_mol = mol_to_fingerprint(mol)\n",
    "        fp_anchor = mol_to_fingerprint(anchor_mol)\n",
    "        tanimoto = DataStructs.TanimotoSimilarity(fp_mol, fp_anchor)\n",
    "        desc_text += f\", Tanimoto: {tanimoto:.2f}\"\n",
    "        print(f\"Tanimoto similarity between {Chem.MolToSmiles(mol)} and anchor: {tanimoto:.2f}\")\n",
    "\n",
    "    # Draw text size and dynamically fit\n",
    "    draw_temp = ImageDraw.Draw(img)\n",
    "    max_width = img.width - 10\n",
    "    font_size = 48\n",
    "    while font_size > 8:\n",
    "        try:\n",
    "            font = ImageFont.truetype(\"/System/Library/Fonts/Supplemental/Arial.ttf\", size=font_size)\n",
    "        except OSError:\n",
    "            font = ImageFont.load_default()\n",
    "        bbox = draw_temp.textbbox((0,0), desc_text, font=font)\n",
    "        text_width = bbox[2] - bbox[0]\n",
    "        text_height = bbox[3] - bbox[1]\n",
    "        if text_width <= max_width:\n",
    "            break\n",
    "        font_size -= 2\n",
    "\n",
    "    # Create new image\n",
    "    total_height = img.height + text_height + 10\n",
    "    new_img = Image.new(\"RGB\", (img.width, total_height), \"white\")\n",
    "    new_img.paste(img, (0, 0))\n",
    "\n",
    "    draw = ImageDraw.Draw(new_img)\n",
    "    draw.text(((img.width - text_width)//2, img.height + 5), desc_text, fill=\"black\", font=font)\n",
    "\n",
    "    # Save image\n",
    "    safe_smi = re.sub(r'[^\\w\\-]', '_', smi)\n",
    "    file_path = os.path.join(output_dir, f\"{safe_smi}.png\")\n",
    "    new_img.save(file_path)\n",
    "\n",
    "# SLERP interpolation\n",
    "def slerp(z1, z2, t):\n",
    "    z1 = np.array(z1)\n",
    "    z2 = np.array(z2)\n",
    "    omega = np.arccos(np.clip(np.dot(z1, z2) / (np.linalg.norm(z1) * np.linalg.norm(z2)), -1, 1))\n",
    "    so = np.sin(omega)\n",
    "    if so == 0:\n",
    "        return (1 - t) * z1 + t * z2\n",
    "    return (np.sin((1 - t) * omega) / so) * z1 + (np.sin(t * omega) / so) * z2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d829c8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "from rdkit import Chem, DataStructs\n",
    "\n",
    "def visualize_nearest_neighbors(\n",
    "    latent_df,\n",
    "    latent_key='z',\n",
    "    anchor_idx=None,\n",
    "    output_root=\"images/nearest_neighbors\",\n",
    "    n_neighbors=5,\n",
    "    method='euclidean'  # 'euclidean' or 'tanimoto'\n",
    "):\n",
    "    \"\"\"\n",
    "    Selects a molecule (by anchor_idx if provided, else random) and visualizes its n nearest neighbors.\n",
    "\n",
    "    latent_df: pandas DataFrame with columns ['smiles', 'z']\n",
    "    anchor_idx: index of anchor molecule (int), or None for random\n",
    "    output_root: root directory to save images\n",
    "    n_neighbors: number of neighbors to visualize\n",
    "    method: 'euclidean' (latent space distance) or 'tanimoto' (fingerprint similarity)\n",
    "    \"\"\"\n",
    "\n",
    "    Path(output_root).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Pick anchor molecule\n",
    "    idx = random.randint(0, len(latent_df) - 1) if anchor_idx is None else anchor_idx\n",
    "    anchor_smi = latent_df.iloc[idx]['smiles']\n",
    "    anchor_z = np.array(latent_df.iloc[idx][latent_key])\n",
    "\n",
    "    if method == 'tanimoto':\n",
    "        anchor_mol = Chem.MolFromSmiles(anchor_smi)\n",
    "        fp_anchor = mol_to_fingerprint(anchor_mol)  # Use your fingerprint function\n",
    "        fps = [mol_to_fingerprint(Chem.MolFromSmiles(smi)) for smi in latent_df['smiles']]\n",
    "        similarities = np.array([DataStructs.TanimotoSimilarity(fp_anchor, fp) for fp in fps])\n",
    "        similarities[idx] = -1  # exclude anchor\n",
    "        # remove any 1.0 similarities (exact matches)\n",
    "        similarities[similarities == 1.0] = -1\n",
    "        neighbor_indices = np.argsort(similarities)[::-1][:n_neighbors]  # highest first\n",
    "    else:\n",
    "        latents_array = np.vstack(latent_df[latent_key].to_numpy())\n",
    "        distances = np.linalg.norm(latents_array - anchor_z, axis=1)\n",
    "        distances[idx] = np.inf  # exclude itself\n",
    "        neighbor_indices = np.argsort(distances)[:n_neighbors]\n",
    "\n",
    "    neighbor_smiles = [latent_df.iloc[i]['smiles'] for i in neighbor_indices]\n",
    "\n",
    "    # Create output folder\n",
    "    safe_anchor = re.sub(r'[^\\w\\-]', '_', anchor_smi)\n",
    "    out_dir = Path(output_root) / safe_anchor\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save anchor\n",
    "    anchor_mol = Chem.MolFromSmiles(anchor_smi)\n",
    "    if anchor_mol:\n",
    "        save_molecule_image(anchor_mol, \"ibuprofen\", output_dir=str(out_dir), anchor_mol=anchor_mol)\n",
    "\n",
    "    # Save neighbors\n",
    "    for i, smi in enumerate(neighbor_smiles, 1):\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "        if mol:\n",
    "            save_molecule_image(mol, f\"neighbour{i}\", output_dir=str(out_dir), anchor_mol=anchor_mol)\n",
    "\n",
    "    print(f\"Anchor: {anchor_smi}\")\n",
    "    print(f\"Nearest neighbors: {neighbor_smiles}\")\n",
    "    return idx, anchor_smi, neighbor_smiles\n",
    "\n",
    "\n",
    "# Choose a fixed anchor index for all models\n",
    "anchor_idx = random.randint(0, len(next(iter(latents.values()))) - 1)\n",
    "anchor_idx = 1051396 # Ibuprofen\n",
    "print(f\"Using anchor index: {anchor_idx}\")\n",
    "\n",
    "# Visualize nearest neighbors for each model using the same anchor\n",
    "# for name, latent_df in latents.items():\n",
    "#     parts = name.split('_')\n",
    "#     model, size, dim = parts[1], parts[2], parts[3]\n",
    "#     print(f\"Visualizing nearest neighbors for {model} with latent dim {dim} and dataset size {size}\")\n",
    "#     if 'Base' in model:\n",
    "#         latent_key = 'z'\n",
    "#     elif 'CSVAE' in model or 'DISCoVeR' in model:\n",
    "#         latent_key = 'wz'\n",
    "#     visualize_nearest_neighbors(latent_df, latent_key=latent_key, anchor_idx=anchor_idx, output_root=f\"images/nearest_neighbors/{model}_{size}_{dim}\", n_neighbors=5)\n",
    "\n",
    "# Do raw fingerprint nearest neighbors for comparison\n",
    "visualize_nearest_neighbors(latents['latents_Base_1826415_4'], anchor_idx=anchor_idx, output_root=\"images/nearest_neighbors/fingerprints_full_50\", n_neighbors=5, method='tanimoto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73790a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use metric directly on fingerprints\n",
    "fingerprint_metric_df = pd.read_pickle('data/chembl_35_fg_scaf_curated.pkl')\n",
    "\n",
    "fingerprint_train, fingerprint_test = train_test_split(fingerprint_metric_df, test_size=0.2, random_state=42)\n",
    "fingerprint_val, fingerprint_test = train_test_split(fingerprint_test, test_size=0.2, random_state=42)\n",
    "\n",
    "# select a subset of fingerprints for evaluation\n",
    "fingerprint_train = fingerprint_train.sample(n=10000, random_state=42)\n",
    "\n",
    "nbrs, fingerprints, labels = get_nearest_neighbors(latents=fingerprint_train['fingerprint_array'].to_list(), fg_labels=fingerprint_train['fg_array'].to_list(), n_neighbors=50)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for i in range(len(fingerprints)):\n",
    "    score = metric(nbrs, i, fingerprints, fingerprint_train['fg_array'].sum(), labels, 50)\n",
    "    scores.append(score)\n",
    "\n",
    "print(np.array(scores).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0803dd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use metric directly on fingerprints\n",
    "fingerprint_metric_df = pd.read_csv('data/chembl_35_fg_full.csv')\n",
    "\n",
    "fingerprint_train, fingerprint_test = train_test_split(fingerprint_metric_df, test_size=0.2, random_state=42)\n",
    "fingerprint_val, fingerprint_test = train_test_split(fingerprint_test, test_size=0.2, random_state=42)\n",
    "\n",
    "# select a subset of fingerprints for evaluation\n",
    "fingerprint_train = fingerprint_train.sample(n=10000, random_state=42)\n",
    "\n",
    "fingerprint_train_dataset = FingerprintDataset(fingerprint_train, sparse=True)\n",
    "\n",
    "fingerprint_train_loader = DataLoader(fingerprint_train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Concatenate batches into a single tensor\n",
    "fingerprints = torch.cat([batch[0] for batch in fingerprint_train_loader], dim=0)\n",
    "fg_vectors = torch.cat([batch[1] for batch in fingerprint_train_loader], dim=0)\n",
    "\n",
    "# Convert to numpy if needed\n",
    "fingerprints = fingerprints.numpy()\n",
    "fg_vectors = fg_vectors.numpy()\n",
    "\n",
    "# Now call nearest neighbors\n",
    "nbrs, fingerprints, labels = get_nearest_neighbors(\n",
    "    latents=fingerprints, \n",
    "    fg_labels=fg_vectors, \n",
    "    n_neighbors=50\n",
    ")\n",
    "\n",
    "scores = []\n",
    "\n",
    "for i in range(len(fingerprints)):\n",
    "    score = metric(nbrs, i, fingerprints, fg_vectors.sum(), labels, 50)\n",
    "    scores.append(score)\n",
    "\n",
    "print(np.array(scores).mean())\n",
    "\n",
    "# Get tanimoto similarity matrix\n",
    "tanimoto_sim_matrix = np.zeros((len(fingerprints), len(fingerprints)))\n",
    "\n",
    "for i in range(len(fingerprints)):\n",
    "    for j in range(len(fingerprints)):\n",
    "        tanimoto_sim_matrix[i, j] = TanimotoSimilarity(fingerprint_to_bv(fingerprints[i]), fingerprint_to_bv(fingerprints[j]))\n",
    "\n",
    "# only keep upper triangle\n",
    "tanimoto_sim_matrix = np.triu(tanimoto_sim_matrix, k=1)\n",
    "\n",
    "# get descriptive statistics\n",
    "tanimoto_sim_flat = tanimoto_sim_matrix.flatten()\n",
    "tanimoto_sim_flat = tanimoto_sim_flat[tanimoto_sim_flat > 0]  # keep only positive similarities\n",
    "\n",
    "print(\"Tanimoto Similarity - Descriptive Statistics:\")\n",
    "print(f\"Mean: {tanimoto_sim_flat.mean()}\")\n",
    "print(f\"Median: {np.median(tanimoto_sim_flat)}\")\n",
    "print(f\"Std Dev: {tanimoto_sim_flat.std()}\")\n",
    "print(f\"Max: {tanimoto_sim_flat.max()}\")\n",
    "print(f\"Min: {tanimoto_sim_flat.min()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84201d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fingerprint brightness umap\n",
    "fingerprint_metric_df = pd.read_pickle('data/chembl_35_fg_scaf_curated.pkl')\n",
    "\n",
    "fingerprint_train, fingerprint_test = train_test_split(fingerprint_metric_df, test_size=0.2, random_state=42)\n",
    "fingerprint_val, fingerprint_test = train_test_split(fingerprint_test, test_size=0.2, random_state=42)\n",
    "\n",
    "fingerprint_train_dataset = FingerprintDataset(fingerprint_train, sparse=False)\n",
    "\n",
    "model = BaseVAETrainer.load_from_checkpoint('checkpoints/fg_bvae_4_8/best-checkpoint.ckpt', map_location='cpu').model\n",
    "\n",
    "visualize_latent_space_tanimoto(\n",
    "    model=model,\n",
    "    dataset=fingerprint_train_dataset,\n",
    "    method='umap',\n",
    "    sample_size=100000,\n",
    "    title='Base VAE Latent Space with Tanimoto Brightness Scale (UMAP)',\n",
    "    save_path='figures/fingerprint_latent_space_umap.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353e8b15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkit-thesis-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
