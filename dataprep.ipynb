{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e81113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/damianelkins/miniconda3/envs/rdkit-thesis/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from fg_funcs import mol_to_fingerprint, safe_mol_from_smiles, fg_to_array, fp_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edfdbb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = 'chembl_35_fg_scaf.csv'\n",
    "if os.path.exists(data_path):\n",
    "    chembl = pd.read_csv(data_path)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Dataset not found at {data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84a1b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each fgs entry to a list\n",
    "chembl['fgs'] = chembl['fgs'].apply(lambda x: eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# drop rows with empty fgs\n",
    "chembl = chembl[chembl['fgs'].notna() & (chembl['fgs'].str.len() > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f96eabc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2310581, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chembl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22e09b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique functional groups\n",
    "all_fgs = set()\n",
    "for fgs in chembl['fgs']:\n",
    "    if isinstance(fgs, list):\n",
    "        all_fgs.update(fgs)\n",
    "\n",
    "# Convert functional groups to a list\n",
    "all_fgs = sorted(list(all_fgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8795cb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/24 already processed. Skipping...\n",
      "Chunk 2/24 already processed. Skipping...\n",
      "Chunk 3/24 already processed. Skipping...\n",
      "Chunk 4/24 already processed. Skipping...\n",
      "Chunk 5/24 already processed. Skipping...\n",
      "Chunk 6/24 already processed. Skipping...\n",
      "Chunk 7/24 already processed. Skipping...\n",
      "Chunk 8/24 already processed. Skipping...\n",
      "Chunk 9/24 already processed. Skipping...\n",
      "Chunk 10/24 already processed. Skipping...\n",
      "Chunk 11/24 already processed. Skipping...\n",
      "Chunk 12/24 already processed. Skipping...\n",
      "Chunk 13/24 already processed. Skipping...\n",
      "Chunk 14/24 already processed. Skipping...\n",
      "Chunk 15/24 already processed. Skipping...\n",
      "Chunk 16/24 already processed. Skipping...\n",
      "Chunk 17/24 already processed. Skipping...\n",
      "Chunk 18/24 already processed. Skipping...\n",
      "Chunk 19/24 already processed. Skipping...\n",
      "Chunk 20/24 already processed. Skipping...\n",
      "Chunk 21/24 already processed. Skipping...\n",
      "Processing chunk 22/24...\n",
      "Saving chunk 22/24 to disk...\n",
      "Processing chunk 23/24...\n",
      "Saving chunk 23/24 to disk...\n",
      "Processing chunk 24/24...\n",
      "Saving chunk 24/24 to disk...\n",
      "Final processed dataset shape: (2310581, 4)\n"
     ]
    }
   ],
   "source": [
    "# Define chunk size\n",
    "chunk_size = 100000\n",
    "num_chunks = (len(chembl) // chunk_size) + 1\n",
    "\n",
    "processed_chunks = []\n",
    "\n",
    "for i in range(num_chunks):\n",
    "    if os.path.exists(f\"full_chembl_chunks/full_chembl_chunk_{i}.csv\"):\n",
    "        print(f\"Chunk {i+1}/{num_chunks} already processed. Skipping...\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"Processing chunk {i+1}/{num_chunks}...\")\n",
    "    \n",
    "        # Extract chunk\n",
    "        chunk = chembl.iloc[i*chunk_size : (i+1)*chunk_size].copy()\n",
    "\n",
    "        chunk['mol'] = chunk['smiles'].apply(safe_mol_from_smiles)\n",
    "        chunk.head()\n",
    "\n",
    "        # Fingerprints and functional group arrays\n",
    "        chunk['fingerprint'] = chunk['mol'].apply(mol_to_fingerprint)\n",
    "        chunk['fingerprint_array'] = chunk['fingerprint'].apply(\n",
    "            lambda x: fp_to_array(x) if x is not None else None\n",
    "        )\n",
    "        chunk['fg_array'] = chunk['fgs'].apply(lambda x: fg_to_array(x, all_fgs))\n",
    "\n",
    "        # Convert to numpy arrays\n",
    "        chunk['fingerprint_array'] = chunk['fingerprint_array'].apply(\n",
    "            lambda x: x if isinstance(x, np.ndarray) else np.zeros((2048,), dtype=int)\n",
    "        )\n",
    "        chunk['fg_array'] = chunk['fg_array'].apply(\n",
    "            lambda x: x if isinstance(x, np.ndarray) else np.zeros((len(all_fgs),), dtype=int)\n",
    "        )\n",
    "\n",
    "        # Remove rows where fg_array is all zeros\n",
    "        chunk = chunk[chunk['fg_array'].apply(lambda x: np.any(x))]\n",
    "\n",
    "        # Only keep necessary columns\n",
    "        chunk = chunk[['smiles', 'fgs', 'fingerprint_array', 'fg_array']]\n",
    "\n",
    "        # Save checkpoint (optional, e.g. to CSV for resuming later)\n",
    "        if not os.path.exists(\"full_chembl_chunks\"):\n",
    "            os.makedirs(\"full_chembl_chunks\")\n",
    "        print(f\"Saving chunk {i+1}/{num_chunks} to disk...\")\n",
    "        chunk.to_csv(f\"full_chembl_chunks/full_chembl_chunk_{i}.csv\", index=False)\n",
    "\n",
    "# Combine all processed chunks\n",
    "# load processed chunks\n",
    "processed_chunks = []\n",
    "for i in range(num_chunks):\n",
    "    chunk_path = f\"full_chembl_chunks/full_chembl_chunk_{i}.csv\"\n",
    "    if os.path.exists(chunk_path):\n",
    "        processed_chunk = pd.read_csv(chunk_path)\n",
    "        processed_chunks.append(processed_chunk)\n",
    "    else:\n",
    "        print(f\"Chunk {i+1}/{num_chunks} not found. Skipping...\")\n",
    "chembl_processed = pd.concat(processed_chunks, ignore_index=True)\n",
    "print(f\"Final processed dataset shape: {chembl_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396c8ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to chembl_35_fg_scaf_full.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the processed data to a CSV file\n",
    "output_file = 'chembl_35_fg_full.csv'\n",
    "chembl_processed.to_csv(output_file, index=False)\n",
    "print(f\"Processed data saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkit-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
