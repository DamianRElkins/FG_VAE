{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e81113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "from fg_funcs import mol_to_fingerprint, safe_mol_from_smiles, fg_to_array, fp_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfdbb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = 'data/chembl_35_fg_scaf.csv'\n",
    "if os.path.exists(data_path):\n",
    "    chembl = pd.read_csv(data_path)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Dataset not found at {data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a1b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each fgs entry to a list\n",
    "chembl['fgs'] = chembl['fgs'].apply(lambda x: eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# drop rows with empty fgs\n",
    "chembl = chembl[chembl['fgs'].notna() & (chembl['fgs'].str.len() > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96eabc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chembl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e09b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curate dataset using 50 functional groups\n",
    "fgs_list = []\n",
    "for fgs in chembl['fgs']:\n",
    "    if isinstance(fgs, list):\n",
    "        fgs_list.extend(fgs)\n",
    "sorted_fgs = pd.Series(fgs_list).value_counts().head(50).index.tolist()\n",
    "\n",
    "print(sorted_fgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8795cb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define chunk size\n",
    "chunk_size = 100000\n",
    "num_chunks = (len(chembl) // chunk_size) + 1\n",
    "\n",
    "processed_chunks = []\n",
    "\n",
    "for i in range(num_chunks):\n",
    "    chunk_path = f\"full_chembl_chunks/full_chembl_chunk_{i}.csv\"\n",
    "    if os.path.exists(chunk_path):\n",
    "        print(f\"Chunk {i+1}/{num_chunks} already processed. Skipping...\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"Processing chunk {i+1}/{num_chunks}...\")\n",
    "    \n",
    "        # Extract chunk\n",
    "        chunk = chembl.iloc[i*chunk_size : (i+1)*chunk_size].copy()\n",
    "\n",
    "        chunk['mol'] = chunk['smiles'].apply(safe_mol_from_smiles)\n",
    "        \n",
    "        # Fingerprints and functional group arrays\n",
    "        chunk['fingerprint'] = chunk['mol'].apply(mol_to_fingerprint)\n",
    "        chunk['fingerprint_array'] = chunk['fingerprint'].apply(\n",
    "            lambda x: fp_to_array(x) if x is not None else None\n",
    "        )\n",
    "        chunk['fg_array'] = chunk['fgs'].apply(lambda x: fg_to_array(x, sorted_fgs))\n",
    "\n",
    "        # Convert to numpy arrays\n",
    "        chunk['fingerprint_array'] = chunk['fingerprint_array'].apply(\n",
    "            lambda x: x if isinstance(x, np.ndarray) else np.zeros((2048,), dtype=int)\n",
    "        )\n",
    "        chunk['fg_array'] = chunk['fg_array'].apply(\n",
    "            lambda x: x if isinstance(x, np.ndarray) else np.zeros((len(sorted_fgs),), dtype=int)\n",
    "        )\n",
    "\n",
    "        # Remove rows where fg_array is all zeros\n",
    "        chunk = chunk[chunk['fg_array'].apply(lambda x: np.any(x))]\n",
    "\n",
    "        # Only keep necessary columns\n",
    "        chunk = chunk[['smiles', 'fgs', 'fingerprint_array', 'fg_array']]\n",
    "\n",
    "        # --- INPLACE FIX: Convert arrays to comma-separated strings before saving ---\n",
    "        chunk['fingerprint_array'] = chunk['fingerprint_array'].apply(\n",
    "            lambda x: ','.join(map(str, x.tolist()))\n",
    "        )\n",
    "        chunk['fg_array'] = chunk['fg_array'].apply(\n",
    "            lambda x: ','.join(map(str, x.tolist()))\n",
    "        )\n",
    "\n",
    "        # Save checkpoint\n",
    "        if not os.path.exists(\"full_chembl_chunks\"):\n",
    "            os.makedirs(\"full_chembl_chunks\")\n",
    "        print(f\"Saving chunk {i+1}/{num_chunks} to disk...\")\n",
    "        chunk.to_csv(chunk_path, index=False)\n",
    "\n",
    "# Combine all processed chunks\n",
    "# load processed chunks\n",
    "processed_chunks = []\n",
    "for i in range(num_chunks):\n",
    "    chunk_path = f\"full_chembl_chunks/full_chembl_chunk_{i}.csv\"\n",
    "    if os.path.exists(chunk_path):\n",
    "        processed_chunk = pd.read_csv(chunk_path)\n",
    "        \n",
    "        processed_chunks.append(processed_chunk)\n",
    "    else:\n",
    "        print(f\"Chunk {i+1}/{num_chunks} not found. Skipping...\")\n",
    "        \n",
    "chembl_processed = pd.concat(processed_chunks, ignore_index=True)\n",
    "print(f\"Final processed dataset shape: {chembl_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df0ee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert fg_array to sparse components\n",
    "chembl_processed['fg_data'] = chembl_processed['fg_array'].apply(\n",
    "    lambda x: sparse.csr_matrix(np.fromstring(x, sep=','))\n",
    ")\n",
    "chembl_processed['fg_data_values'] = chembl_processed['fg_data'].apply(lambda x: x.data.tolist())\n",
    "chembl_processed['fg_indices'] = chembl_processed['fg_data'].apply(lambda x: x.indices.tolist())\n",
    "chembl_processed['fg_indptr'] = chembl_processed['fg_data'].apply(lambda x: x.indptr.tolist())\n",
    "chembl_processed['fg_length'] = chembl_processed['fg_data'].apply(lambda x: x.shape[1])\n",
    "\n",
    "# Same for fingerprint_array\n",
    "chembl_processed['fp_data'] = chembl_processed['fingerprint_array'].apply(\n",
    "    lambda x: sparse.csr_matrix(np.fromstring(x, sep=','))\n",
    ")\n",
    "chembl_processed['fp_data_values'] = chembl_processed['fp_data'].apply(lambda x: x.data.tolist())\n",
    "chembl_processed['fp_indices'] = chembl_processed['fp_data'].apply(lambda x: x.indices.tolist())\n",
    "chembl_processed['fp_indptr'] = chembl_processed['fp_data'].apply(lambda x: x.indptr.tolist())\n",
    "chembl_processed['fp_length'] = chembl_processed['fp_data'].apply(lambda x: x.shape[1])\n",
    "\n",
    "chembl_processed = chembl_processed.drop(columns=['fg_array', 'fingerprint_array', 'fg_data', 'fp_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396c8ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Save the processed data to a CSV file\n",
    "output_file = 'data/chembl_35_fg_full.csv'\n",
    "chembl_processed.to_csv(output_file, index=False)\n",
    "print(f\"Processed data saved to {output_file}\")\n",
    "\n",
    "chunks_dir = \"full_chembl_chunks\"\n",
    "if os.path.exists(chunks_dir):\n",
    "    shutil.rmtree(chunks_dir)\n",
    "    print(f\"Deleted directory: {chunks_dir}\")\n",
    "else:\n",
    "    print(f\"Directory not found: {chunks_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ef0616",
   "metadata": {},
   "outputs": [],
   "source": [
    "chembl_processed.head(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkit-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
